{"cells":[{"attachments":{},"cell_type":"markdown","metadata":{},"source":["  # CORAL for ST"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["  Creating something like CellDART but just using coral loss"]},{"cell_type":"code","execution_count":1,"metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["/tmp/ipykernel_12764/1192969662.py:7: TqdmExperimentalWarning: Using `tqdm.autonotebook.tqdm` in notebook mode. Use `tqdm.tqdm` instead to force console mode (e.g. in jupyter console)\n","  from tqdm.autonotebook import tqdm\n"]}],"source":["import argparse\n","import os\n","import datetime\n","from copy import deepcopy\n","import warnings\n","\n","from tqdm.autonotebook import tqdm\n","import matplotlib.pyplot as plt\n","import numpy as np\n","import yaml\n","\n","\n","import torch\n","from torch.nn import functional as F\n","from torch import nn\n","\n","from src.da_models.coral import CORAL\n","from src.da_models.datasets import SpotDataset\n","from src.da_models.utils import initialize_weights\n","from src.utils.dupstdout import DupStdout\n","from src.utils.data_loading import (\n","    load_spatial,\n","    load_sc,\n","    get_selected_dir,\n","    get_model_rel_path,\n",")\n","from src.utils.evaluation import format_iters\n","\n","# datetime object containing current date and time\n","script_start_time = datetime.datetime.now(datetime.timezone.utc)\n","\n"]},{"cell_type":"code","execution_count":2,"metadata":{},"outputs":[{"data":{"text/plain":["_StoreAction(option_strings=['--cuda', '-c'], dest='cuda', nargs=None, const=None, default=None, type=None, choices=None, help='gpu index to use', metavar=None)"]},"execution_count":2,"metadata":{},"output_type":"execute_result"}],"source":["parser = argparse.ArgumentParser(\n","    description=(\n","        \"Creating something like CellDART \"\n","        \"but it actually follows Adda in PyTorch as a first step\"\n","    )\n",")\n","parser.add_argument(\n","    \"--config_fname\",\n","    \"-f\",\n","    type=str,\n","    help=\"Name of the config file to use\",\n",")\n","parser.add_argument(\n","    \"--njobs\",\n","    type=int,\n","    default=0,\n","    help=\"Number of jobs to use for parallel processing.\",\n",")\n","parser.add_argument(\n","    \"--cuda\",\n","    \"-c\",\n","    default=None,\n","    help=\"gpu index to use\",\n",")\n"]},{"cell_type":"code","execution_count":3,"metadata":{},"outputs":[],"source":["CONFIG_FNAME = \"coral.yml\"\n","NUM_WORKERS = 16\n","CUDA_INDEX = None\n","\n","# args = parser.parse_args()\n","# CONFIG_FNAME = args.config_fname\n","# CUDA_INDEX = args.cuda\n","# NUM_WORKERS = args.njobs\n","\n"]},{"cell_type":"code","execution_count":4,"metadata":{},"outputs":[],"source":["torch_params = {}\n","\n","torch_params[\"manual_seed\"] = 3583\n","\n"]},{"cell_type":"code","execution_count":5,"metadata":{},"outputs":[],"source":["data_params = {}\n","# Data path and parameters\n","data_params[\"data_dir\"] = \"data\"\n","data_params[\"train_using_all_st_samples\"] = False\n","data_params[\"n_markers\"] = 20\n","data_params[\"all_genes\"] = False\n","\n","# Pseudo-spot parameters\n","data_params[\"n_spots\"] = 20000\n","data_params[\"n_mix\"] = 8\n","\n","# ST spot parameters\n","data_params[\"st_split\"] = False\n","data_params[\"sample_id_n\"] = \"151673\"\n","\n","# Scaler parameter\n","data_params[\"scaler_name\"] = \"standard\"\n","\n"]},{"cell_type":"code","execution_count":6,"metadata":{},"outputs":[],"source":["MODEL_NAME = \"CORAL\"\n","\n","model_params = {}\n","\n","# Model parameters\n","\n","model_params[\"model_version\"] = \"v1\"\n","\n","model_params[\"coral_kwargs\"] = {\n","    \"emb_dim\": 64,\n","}\n","\n"]},{"cell_type":"code","execution_count":7,"metadata":{},"outputs":[],"source":["train_params = {}\n","\n","train_params[\"batch_size\"] = 1024\n","\n","# Pretraining parameters\n","# SAMPLE_ID_N = \"151673\"\n","\n","# train_params[\"initial_train_epochs\"] = 100\n","\n","# train_params[\"early_stop_crit\"] = 100\n","# train_params[\"min_epochs\"] = 0.4 * train_params[\"initial_train_epochs\"]\n","\n","# Adversarial training parameters\n","train_params[\"epochs\"] = 200\n","train_params[\"early_stop_crit_adv\"] = train_params[\"epochs\"]\n","train_params[\"min_epochs_adv\"] =  0.4 * train_params[\"epochs\"]\n","\n","\n","# train_params[\"enc_lr\"] = 0.0002\n","# train_params[\"alpha\"] = 2\n","# train_params[\"dis_loop_factor\"] = 5\n","# train_params[\"adam_beta1\"] = 0.5\n","train_params[\"lambda\"] = 1\n","train_params[\"opt_kwargs\"] = {\"lr\": 0.0002}"]},{"cell_type":"code","execution_count":8,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["data_params:\n","  all_genes: false\n","  data_dir: data\n","  n_markers: 20\n","  n_mix: 8\n","  n_spots: 20000\n","  sample_id_n: '151673'\n","  scaler_name: standard\n","  st_split: false\n","  train_using_all_st_samples: false\n","model_params:\n","  coral_kwargs:\n","    emb_dim: 64\n","  model_version: v1\n","torch_params:\n","  manual_seed: 3583\n","train_params:\n","  batch_size: 1024\n","  coral_lambda: 1\n","  early_stop_crit_adv: 200\n","  epochs: 200\n","  min_epochs_adv: 80.0\n","  opt_kwargs:\n","    lr: 0.0002\n","\n"]}],"source":["config = {\n","    \"torch_params\": torch_params,\n","    \"data_params\": data_params,\n","    \"model_params\": model_params,\n","    \"train_params\": train_params,\n","}\n","\n","if not os.path.exists(os.path.join(\"configs\", MODEL_NAME)):\n","    os.makedirs(os.path.join(\"configs\", MODEL_NAME))\n","\n","with open(os.path.join(\"configs\", MODEL_NAME, CONFIG_FNAME), \"w\") as f:\n","    yaml.safe_dump(config, f)\n","\n","with open(os.path.join(\"configs\", MODEL_NAME, CONFIG_FNAME), \"r\") as f:\n","    config = yaml.safe_load(f)\n","\n","print(yaml.safe_dump(config))\n","\n","torch_params = config[\"torch_params\"]\n","data_params = config[\"data_params\"]\n","model_params = config[\"model_params\"]\n","train_params = config[\"train_params\"]\n","\n"]},{"cell_type":"code","execution_count":9,"metadata":{},"outputs":[],"source":["if CUDA_INDEX is not None:\n","    device = torch.device(f\"cuda:{CUDA_INDEX}\" if torch.cuda.is_available() else \"cpu\")\n","else:\n","    device = torch.device(f\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","if device == \"cpu\":\n","    warnings.warn(\"Using CPU\", stacklevel=2)\n","\n"]},{"cell_type":"code","execution_count":10,"metadata":{},"outputs":[],"source":["if \"manual_seed\" in torch_params:\n","    torch_seed = torch_params[\"manual_seed\"]\n","    torch_seed_path = str(torch_params[\"manual_seed\"])\n","else:\n","    torch_seed = int(script_start_time.timestamp())\n","    # torch_seed_path = script_start_time.strftime(\"%Y-%m-%d_%Hh%Mm%Ss\")\n","    torch_seed_path = \"random\"\n","\n","torch.manual_seed(torch_seed)\n","np.random.seed(torch_seed)\n","\n"]},{"cell_type":"code","execution_count":11,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["model/CORAL/20markers/standard/8mix_20000spots/v1/3583\n"]}],"source":["model_folder = get_model_rel_path(\n","    MODEL_NAME,\n","    model_params[\"model_version\"],\n","    scaler_name=data_params[\"scaler_name\"],\n","    n_markers=data_params[\"n_markers\"],\n","    all_genes=data_params[\"all_genes\"],\n","    n_mix=data_params[\"n_mix\"],\n","    n_spots=data_params[\"n_spots\"],\n","    st_split=data_params[\"st_split\"],\n","    torch_seed_path=torch_seed_path,\n",")\n","model_folder = os.path.join(\"model\", model_folder)\n","\n","if not os.path.isdir(model_folder):\n","    os.makedirs(model_folder)\n","    print(model_folder)\n","\n"]},{"cell_type":"markdown","metadata":{},"source":["  # Data load"]},{"cell_type":"code","execution_count":12,"metadata":{},"outputs":[],"source":["selected_dir = get_selected_dir(\n","    data_params[\"data_dir\"], data_params[\"n_markers\"], data_params[\"all_genes\"]\n",")\n","\n","# Load spatial data\n","mat_sp_d, mat_sp_train, st_sample_id_l = load_spatial(\n","    selected_dir,\n","    data_params[\"scaler_name\"],\n","    train_using_all_st_samples=data_params[\"train_using_all_st_samples\"],\n","    st_split=data_params[\"st_split\"],\n",")\n","\n","# Load sc data\n","sc_mix_d, lab_mix_d, sc_sub_dict, sc_sub_dict2 = load_sc(\n","    selected_dir,\n","    data_params[\"scaler_name\"],\n","    n_mix=data_params[\"n_mix\"],\n","    n_spots=data_params[\"n_spots\"],\n",")\n","\n"]},{"cell_type":"markdown","metadata":{},"source":["  # Training: Adversarial domain adaptation for cell fraction estimation"]},{"cell_type":"markdown","metadata":{},"source":["  ## Prepare dataloaders"]},{"cell_type":"code","execution_count":13,"metadata":{},"outputs":[],"source":["### source dataloaders\n","source_train_set = SpotDataset(sc_mix_d[\"train\"], lab_mix_d[\"train\"])\n","source_val_set = SpotDataset(sc_mix_d[\"val\"], lab_mix_d[\"val\"])\n","source_test_set = SpotDataset(sc_mix_d[\"test\"], lab_mix_d[\"test\"])\n","\n","dataloader_source_train = torch.utils.data.DataLoader(\n","    source_train_set,\n","    batch_size=train_params[\"batch_size\"],\n","    shuffle=True,\n","    num_workers=NUM_WORKERS,\n","    pin_memory=False,\n",")\n","dataloader_source_val = torch.utils.data.DataLoader(\n","    source_val_set,\n","    batch_size=train_params[\"batch_size\"],\n","    shuffle=False,\n","    num_workers=NUM_WORKERS,\n","    pin_memory=False,\n",")\n","dataloader_source_test = torch.utils.data.DataLoader(\n","    source_test_set,\n","    batch_size=train_params[\"batch_size\"],\n","    shuffle=False,\n","    num_workers=NUM_WORKERS,\n","    pin_memory=False,\n",")\n","\n","### target dataloaders\n","target_train_set_d = {}\n","dataloader_target_train_d = {}\n","if data_params[\"st_split\"]:\n","    target_val_set_d = {}\n","    target_test_set_d = {}\n","\n","    dataloader_target_val_d = {}\n","    dataloader_target_test_d = {}\n","    for sample_id in st_sample_id_l:\n","        target_train_set_d[sample_id] = SpotDataset(mat_sp_d[sample_id][\"train\"])\n","        target_val_set_d[sample_id] = SpotDataset(mat_sp_d[sample_id][\"val\"])\n","        target_test_set_d[sample_id] = SpotDataset(mat_sp_d[sample_id][\"test\"])\n","\n","        dataloader_target_train_d[sample_id] = torch.utils.data.DataLoader(\n","            target_train_set_d[sample_id],\n","            batch_size=train_params[\"batch_size\"],\n","            shuffle=True,\n","            num_workers=NUM_WORKERS,\n","            pin_memory=False,\n","        )\n","        dataloader_target_val_d[sample_id] = torch.utils.data.DataLoader(\n","            target_val_set_d[sample_id],\n","            batch_size=train_params[\"batch_size\"],\n","            shuffle=False,\n","            num_workers=NUM_WORKERS,\n","            pin_memory=False,\n","        )\n","        dataloader_target_test_d[sample_id] = torch.utils.data.DataLoader(\n","            target_test_set_d[sample_id],\n","            batch_size=train_params[\"batch_size\"],\n","            shuffle=False,\n","            num_workers=NUM_WORKERS,\n","            pin_memory=False,\n","        )\n","\n","else:\n","    target_test_set_d = {}\n","    dataloader_target_test_d = {}\n","\n","    for sample_id in st_sample_id_l:\n","        target_train_set_d[sample_id] = SpotDataset(mat_sp_d[sample_id][\"train\"])\n","        dataloader_target_train_d[sample_id] = torch.utils.data.DataLoader(\n","            target_train_set_d[sample_id],\n","            batch_size=train_params[\"batch_size\"],\n","            shuffle=True,\n","            num_workers=NUM_WORKERS,\n","            pin_memory=False,\n","        )\n","\n","        target_test_set_d[sample_id] = SpotDataset(\n","            deepcopy(mat_sp_d[sample_id][\"test\"])\n","        )\n","        dataloader_target_test_d[sample_id] = torch.utils.data.DataLoader(\n","            target_test_set_d[sample_id],\n","            batch_size=train_params[\"batch_size\"],\n","            shuffle=False,\n","            num_workers=NUM_WORKERS,\n","            pin_memory=False,\n","        )\n","\n","\n","if data_params[\"train_using_all_st_samples\"]:\n","    target_train_set = SpotDataset(mat_sp_train)\n","    dataloader_target_train = torch.utils.data.DataLoader(\n","        target_train_set,\n","        batch_size=train_params[\"batch_size\"],\n","        shuffle=True,\n","        num_workers=NUM_WORKERS,\n","        pin_memory=True,\n","    )\n","\n"]},{"cell_type":"markdown","metadata":{},"source":["  ## Define Model"]},{"cell_type":"code","execution_count":14,"metadata":{},"outputs":[{"data":{"text/plain":["CORAL(\n","  (encoder): MLP(\n","    (encoder): Sequential(\n","      (0): Linear(in_features=360, out_features=1024, bias=True)\n","      (1): BatchNorm1d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (2): LeakyReLU(negative_slope=0.01)\n","      (3): Linear(in_features=1024, out_features=512, bias=True)\n","      (4): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (5): LeakyReLU(negative_slope=0.01)\n","      (6): Linear(in_features=512, out_features=64, bias=True)\n","      (7): ELU(alpha=1.0)\n","    )\n","  )\n","  (source_encoder): MLP(\n","    (encoder): Sequential(\n","      (0): Linear(in_features=360, out_features=1024, bias=True)\n","      (1): BatchNorm1d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (2): LeakyReLU(negative_slope=0.01)\n","      (3): Linear(in_features=1024, out_features=512, bias=True)\n","      (4): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (5): LeakyReLU(negative_slope=0.01)\n","      (6): Linear(in_features=512, out_features=64, bias=True)\n","      (7): ELU(alpha=1.0)\n","    )\n","  )\n","  (target_encoder): MLP(\n","    (encoder): Sequential(\n","      (0): Linear(in_features=360, out_features=1024, bias=True)\n","      (1): BatchNorm1d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (2): LeakyReLU(negative_slope=0.01)\n","      (3): Linear(in_features=1024, out_features=512, bias=True)\n","      (4): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (5): LeakyReLU(negative_slope=0.01)\n","      (6): Linear(in_features=512, out_features=64, bias=True)\n","      (7): ELU(alpha=1.0)\n","    )\n","  )\n","  (clf): MLP(\n","    (encoder): Sequential(\n","      (0): Linear(in_features=64, out_features=33, bias=True)\n","      (1): LogSoftmax(dim=1)\n","    )\n","  )\n",")"]},"execution_count":14,"metadata":{},"output_type":"execute_result"}],"source":["\n"]},{"cell_type":"markdown","metadata":{},"source":["  ## Pretrain"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["criterion_clf = nn.KLDivLoss(reduction=\"batchmean\")\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["def model_loss(x, y_true, model):\n","    x = x.to(torch.float32).to(device)\n","    y_true = y_true.to(torch.float32).to(device)\n","\n","    y_pred = model(x)\n","\n","    loss = criterion_clf(y_pred, y_true)\n","\n","    return loss\n","\n","\n","def run_pretrain_epoch(model, dataloader, optimizer=None, scheduler=None, inner=None):\n","    loss_running = []\n","    lr_running = []\n","    mean_weights = []\n","    \n","\n","    is_training = model.training and optimizer\n","\n","    for _, batch in enumerate(dataloader):\n","        loss = model_loss(*batch, model)\n","        loss_running.append(loss.item())\n","        mean_weights.append(len(batch))  # we will weight average by batch size later\n","\n","        if is_training:\n","            optimizer.zero_grad()\n","            loss.backward()\n","            optimizer.step()\n","            if scheduler:\n","                lr_running.append(scheduler.get_last_lr()[-1])\n","                scheduler.step()\n","        if inner:\n","            inner.update(1)\n","    return loss_running, mean_weights, lr_running\n","\n","\n","def compute_acc(dataloader, model):\n","\n","    model.eval()\n","    with torch.no_grad():\n","        loss_running, mean_weights, _ = run_pretrain_epoch(model, dataloader)\n","\n","    return np.average(loss_running, weights=mean_weights)\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["if train_params.get(\"pretraining\", False):\n","\n","    pretrain_folder = os.path.join(model_folder, \"pretrain\")\n","\n","    model = CORAL(\n","        inp_dim=sc_mix_d[\"train\"].shape[1],\n","        ncls_source=lab_mix_d[\"train\"].shape[1],\n","        **model_params[\"coral_kwargs\"]\n","    )\n","    model.apply(initialize_weights)\n","    model.to(device)\n","\n","    pre_optimizer = torch.optim.AdamW(\n","        model.parameters(),\n","        lr=train_params[\"initial_train_lr\"],\n","        betas=(0.9, 0.999),\n","        eps=1e-07,\n","    )\n","\n","    pre_scheduler = torch.optim.lr_scheduler.OneCycleLR(\n","        pre_optimizer,\n","        max_lr=train_params[\"initial_train_lr\"],\n","        steps_per_epoch=len(dataloader_source_train),\n","        epochs=train_params[\"initial_train_epochs\"],\n","    )\n","\n","    model.pretraining()\n","\n","    if not os.path.isdir(pretrain_folder):\n","        os.makedirs(pretrain_folder)\n","    # Initialize lists to store loss and accuracy values\n","    loss_history = []\n","    loss_history_val = []\n","\n","    loss_history_running = []\n","\n","    lr_history_running = []\n","\n","    # Early Stopping\n","    best_loss_val = np.inf\n","    early_stop_count = 0\n","\n","    # Train\n","    with DupStdout().dup_to_file(\n","        os.path.join(pretrain_folder, \"log.txt\"), \"w\"\n","    ) as f_log:\n","        print(\"Start pretrain...\")\n","        outer = tqdm(\n","            total=train_params[\"initial_train_epochs\"], desc=\"Epochs\", position=0\n","        )\n","        inner = tqdm(total=len(dataloader_source_train), desc=f\"Batch\", position=1)\n","\n","        tqdm.write(\" Epoch | Train Loss | Val Loss   | Next LR    \")\n","        tqdm.write(\"----------------------------------------------\")\n","        checkpoint = {\n","            \"epoch\": -1,\n","            \"model\": model,\n","            \"optimizer\": pre_optimizer,\n","            \"scheduler\": pre_scheduler,\n","            # 'scaler': scaler\n","        }\n","        for epoch in range(train_params[\"initial_train_epochs\"]):\n","            inner.refresh()  # force print final state\n","            inner.reset()  # reuse bar\n","            checkpoint[\"epoch\"] = epoch\n","\n","            # Train mode\n","            model.train()\n","\n","            loss_running, mean_weights, lr_running = run_pretrain_epoch(\n","                model,\n","                dataloader_source_train,\n","                optimizer=pre_optimizer,\n","                scheduler=pre_scheduler,\n","                inner=inner,\n","            )\n","\n","            loss_history.append(np.average(loss_running, weights=mean_weights))\n","            loss_history_running.append(loss_running)\n","            lr_history_running.append(lr_running)\n","\n","            # Evaluate mode\n","            model.eval()\n","            with torch.no_grad():\n","                curr_loss_val = compute_acc(dataloader_source_val, model)\n","                loss_history_val.append(curr_loss_val)\n","\n","            # Print the results\n","            outer.update(1)\n","\n","            out_string = (\n","                f\" {epoch:5d} \"\n","                f\"| {loss_history[-1]:<10.8f} \"\n","                f\"| {curr_loss_val:<10.8f} \"\n","                f\"| {pre_scheduler.get_last_lr()[-1]:<10.5} \"\n","            )\n","\n","            # Save the best weights\n","            if curr_loss_val < best_loss_val:\n","                best_loss_val = curr_loss_val\n","                torch.save(checkpoint, os.path.join(pretrain_folder, f\"best_model.pth\"))\n","                early_stop_count = 0\n","\n","                out_string += \"<-- new best val loss\"\n","\n","            tqdm.write(out_string)\n","\n","            # Save checkpoint every 10\n","            if epoch % 10 == 0 or epoch >= train_params[\"initial_train_epochs\"] - 1:\n","                torch.save(\n","                    checkpoint, os.path.join(pretrain_folder, f\"checkpt{epoch}.pth\")\n","                )\n","\n","            # check to see if validation loss has plateau'd\n","            if (\n","                early_stop_count >= train_params[\"early_stop_crit\"]\n","                and epoch >= train_params[\"min_epochs\"] - 1\n","            ):\n","                tqdm.write(\n","                    f\"Validation loss plateaued after {early_stop_count} at epoch {epoch}\"\n","                )\n","                torch.save(\n","                    checkpoint, os.path.join(pretrain_folder, f\"earlystop{epoch}.pth\")\n","                )\n","                break\n","\n","            early_stop_count += 1\n","\n","    lr_history_running[-1].append(pre_scheduler.get_last_lr()[-1])\n","\n","    # Save final model\n","    best_checkpoint = torch.load(os.path.join(pretrain_folder, f\"best_model.pth\"))\n","    torch.save(best_checkpoint, os.path.join(pretrain_folder, f\"final_model.pth\"))\n","\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["if train_params.get(\"pretraining\", False):\n","\n","    best_checkpoint = torch.load(os.path.join(pretrain_folder, f\"final_model.pth\"))\n","\n","    best_epoch = best_checkpoint[\"epoch\"]\n","    best_loss_val = loss_history_val[best_epoch]\n","\n","    fig, axs = plt.subplots(2, 1, sharex=True, figsize=(6, 4), layout=\"constrained\")\n","\n","    axs[0].plot(*format_iters(loss_history_running), label=\"Training\", linewidth=0.5)\n","    axs[0].plot(loss_history_val, label=\"Validation\")\n","    axs[0].axvline(best_epoch, color=\"tab:green\")\n","\n","    axs[0].set_ylim(bottom=0)\n","    axs[0].grid(which=\"major\")\n","    axs[0].minorticks_on()\n","    axs[0].grid(which=\"minor\", alpha=0.2)\n","\n","    axs[0].text(\n","        x=best_epoch + (2 if best_epoch < len(loss_history) * 0.75 else -2),\n","        y=max(loss_history + loss_history_val) * 0.5,\n","        s=f\"Best val. loss:\\n{best_loss_val:.4f} at epoch {best_epoch}\",\n","        ha=\"left\" if best_epoch < len(loss_history) * 0.75 else \"right\",\n","        size=\"x-small\",\n","    )\n","\n","    # axs[0].set_xlabel(\"Epoch\")\n","    axs[0].set_title(\"Cross-Entropy Loss\")\n","    axs[0].legend()\n","\n","    # lr history\n","    iters_by_epoch, lr_history_running_flat = format_iters(\n","        lr_history_running, startpoint=True\n","    )\n","    axs[1].plot(iters_by_epoch, lr_history_running_flat)\n","    axs[1].axvline(best_checkpoint[\"epoch\"], ymax=2, clip_on=False, color=\"tab:green\")\n","\n","    axs[1].set_ylim(bottom=0)\n","    axs[1].grid(which=\"major\")\n","    axs[1].minorticks_on()\n","    axs[1].grid(which=\"minor\", alpha=0.2)\n","\n","    best_epoch_idx = np.where(iters_by_epoch == best_epoch)[0][0]\n","    axs[1].text(\n","        x=best_epoch + (2 if best_epoch < len(loss_history) * 0.75 else -2),\n","        y=np.median(lr_history_running_flat),\n","        s=f\"LR:\\n{lr_history_running_flat[best_epoch_idx]:.4} at epoch {best_epoch}\",\n","        ha=\"left\" if best_epoch < len(loss_history) * 0.75 else \"right\",\n","        size=\"x-small\",\n","    )\n","\n","    axs[1].set_xlabel(\"Epoch\")\n","    axs[1].set_title(\"Learning Rate\")\n","\n","    plt.savefig(os.path.join(pretrain_folder, \"train_plots.png\"), bbox_inches=\"tight\")\n","\n","    plt.show(block=False)\n","\n"]},{"cell_type":"markdown","metadata":{},"source":["  ## Adversarial Adaptation"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["advtrain_folder = os.path.join(model_folder, \"advtrain\")\n","\n","if not os.path.isdir(advtrain_folder):\n","    os.makedirs(advtrain_folder)\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["def model_adv_loss(\n","    x_source,\n","    x_target,\n","    y_source,\n","    model,\n","    two_step=False,\n","    source_first=True,\n","    optimizer=None,\n","):\n","\n","    if two_step:\n","        if source_first:\n","            y_pred_source = model(x_source)\n","            y_pred_target = model(x_target)\n","        else:\n","            y_pred_target = model(x_target)\n","            y_pred_source = model(x_source)\n","    else:\n","        y_pred = model(torch.cat([x_source, x_target], dim=0))\n","        y_pred_source, y_pred_target = torch.split(y_pred, [len(x_source), len(x_target)])\n","\n","    loss_clf = criterion_clf(y_pred_source, y_source)\n","    loss_dis = criterion_dis(y_pred_source, y_pred_target)\n","    loss = loss_clf + loss_dis * train_params[\"lambda\"]\n","    update_weights(optimizer, loss)\n","\n","\n","    return loss, loss_dis, loss_clf\n","\n","\n","\n","# def target_step(x_target, model, optimizer):\n","#     if optimizer is not None:\n","#         clf_rq_bak = dict(\n","#             (\n","#                 (name, param.requires_grad)\n","#                 for name, param in model.clf.named_parameters()\n","#             )\n","#         )\n","\n","#     y_dis_target, y_dis_target_pred, loss_dis_target = target_pass(x_target, model)\n","#     loss = loss_dis_target * train_params[\"lambda\"]\n","\n","#     if optimizer is not None:\n","#         update_weights(optimizer, loss)\n","#         for name, param in model.clf.named_parameters():\n","#             param.requires_grad = clf_rq_bak[name]\n","\n","#     return y_dis_target, y_dis_target_pred, loss_dis_target\n","\n","\n","# def source_step(x_source, y_source, model, optimizer):\n","#     y_dis_source, y_dis_source_pred, loss_clf, loss_dis_source = source_pass(\n","#         x_source, y_source, model\n","#     )\n","#     loss = loss_clf + loss_dis_source * train_params[\"lambda\"]\n","#     update_weights(optimizer, loss)\n","#     return y_dis_source, y_dis_source_pred, loss_clf, loss_dis_source\n","\n","\n","def update_weights(optimizer, loss):\n","    if optimizer is not None:\n","        optimizer.zero_grad()\n","        loss.backward()\n","        optimizer.step()\n","\n","\n","# def target_pass(x_target, model):\n","#     y_dis_target = torch.ones(\n","#         x_target.shape[0], device=device, dtype=x_target.dtype\n","#     ).view(-1, 1)\n","#     _, y_dis_target_pred = model(x_target, clf=False)\n","#     loss_dis_target = criterion_dis(y_dis_target_pred, y_dis_target)\n","#     return y_dis_target, y_dis_target_pred, loss_dis_target\n","\n","\n","# def source_pass(x_source, y_source, model):\n","#     y_dis_source = torch.zeros(\n","#         x_source.shape[0], device=device, dtype=x_source.dtype\n","#     ).view(-1, 1)\n","#     y_clf, y_dis_source_pred = model(x_source, clf=True)\n","#     loss_clf = criterion_clf(y_clf, y_source)\n","#     loss_dis_source = criterion_dis(y_dis_source_pred, y_dis_source)\n","#     return y_dis_source, y_dis_source_pred, loss_clf, loss_dis_source\n","\n","\n","def run_epoch(\n","    dataloader_source,\n","    dataloader_target,\n","    model,\n","    tqdm_bar=None,\n","    **kwargs,\n","):\n","    results_running = {\n","        \"clf\": {\"loss\": [], \"weights\": []},\n","        \"dis\": {\"loss\": [], \"weights\": []},\n","        \"ovr\": {\"loss\": [], \"weights\": []},\n","    }\n","\n","    n_iters = max(len(dataloader_source), len(dataloader_target))\n","\n","    s_iter = iter(dataloader_source)\n","    t_iter = iter(dataloader_target)\n","    for i in range(n_iters):\n","        try:\n","            x_source, y_source = next(s_iter)\n","        except StopIteration:\n","            s_iter = iter(dataloader_source)\n","            x_source, y_source = next(s_iter)\n","        try:\n","            x_target, _ = next(t_iter)\n","        except StopIteration:\n","            t_iter = iter(dataloader_target)\n","            x_target, _ = next(t_iter)\n","\n","        x_source = x_source.to(torch.float32).to(device)\n","        x_target = x_target.to(torch.float32).to(device)\n","        y_source = y_source.to(torch.float32).to(device)\n","\n","        loss, loss_dis, loss_clf = model_adv_loss(x_source, x_target, y_source, model, **kwargs)\n","\n","        results_running[\"dis\"][\"loss\"].append(loss_dis.item())\n","        results_running[\"clf\"][\"loss\"].append(loss_clf.item())\n","        results_running[\"ovr\"][\"loss\"].append(loss.item())\n","\n","\n","        results_running[\"dis\"][\"weights\"].append((len(x_source)+len(x_target))/2)\n","        results_running[\"clf\"][\"weights\"].append(len(x_source))\n","        results_running[\"ovr\"][\"weights\"].append((len(x_source)+len(x_target))/2 + len(x_source))\n","\n","        if tqdm_bar is not None:\n","            tqdm_bar.update(1)\n","\n","    return results_running\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["def train_adversarial_iters(\n","    model,\n","    save_folder,\n","    dataloader_source_train,\n","    dataloader_source_val,\n","    dataloader_target_train,\n","):\n","    model.to(device)\n","    model.advtraining()\n","\n","    optimizer = torch.optim.AdamW(model.parameters(), **train_params[\"opt_kwargs\"])\n","    # scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(\n","    #     optimizer, **train_params[\"plateau_kwargs\"]\n","    # )\n","\n","    # iters = -(max_len_dataloader // -(1 + DIS_LOOP_FACTOR))  # ceiling divide\n","\n","    max_len_dataloader = max(len(dataloader_source_train), len(dataloader_target_train))\n","    iters_val = max(len(dataloader_source_val), len(dataloader_target_train))\n","\n","\n","    results_template = {\n","        \"clf\": {\"loss\": [], \"weights\": []},\n","        \"dis\": {\"loss\": [], \"weights\": []},\n","        \"ovr\": {\"loss\": [], \"weights\": []},\n","    }\n","    results_history = deepcopy(results_template)\n","    results_history_val = deepcopy(results_template)\n","    results_history_running = deepcopy(results_template)\n","\n","    # Early Stopping\n","    best_loss_val = np.inf\n","    early_stop_count = 0\n","    with DupStdout().dup_to_file(os.path.join(save_folder, \"log.txt\"), \"w\") as f_log:\n","        # Train\n","        print(\"Start adversarial training...\")\n","        outer = tqdm(total=train_params[\"epochs\"], desc=\"Epochs\", position=0)\n","        inner1 = tqdm(total=max_len_dataloader, desc=f\"Batch\", position=1)\n","\n","        tqdm.write(\" Epoch || KLDiv.          || Coral           || Overall         \")\n","        tqdm.write(\"       || Train  | Val.   || Train  | Val.   || Train  | Val.   \")\n","        tqdm.write(\"----------------------------------------------------------------\")\n","        checkpoint = {\n","            \"epoch\": -1,\n","            \"model\": model,\n","            \"optimizer\": optimizer,\n","        }\n","        for epoch in range(train_params[\"epochs\"]):\n","            inner1.refresh()  # force print final state\n","            inner1.reset()  # reuse bar\n","\n","            checkpoint[\"epoch\"] = epoch\n","\n","            results_running = run_epoch(\n","                dataloader_source_train,\n","                dataloader_target_train,\n","                model,\n","                tqdm_bar=inner,\n","                optimizer=optimizer,\n","                two_step=train_params[\"two_step\"],\n","                source_first=train_params.get(\"source_first\", True),\n","            )\n","\n","\n","            for goal_k in results_running:\n","                for metric_k in results_running[goal_k]:\n","                    results_history[goal_k][metric_k].append(np.average(\n","                        results_running[goal_k][metric_k],\n","                        weights=results_running[goal_k][\"weights\"],\n","                    ))\n","            for goal_k in results_running:\n","                for metric_k in results_running[goal_k]:\n","                    results_history_running[goal_k][metric_k].append(results_running[goal_k][metric_k])\n","\n","\n","            model.eval()\n","            with torch.no_grad():\n","                results_val = run_epoch(\n","                    dataloader_source_val, dataloader_target_train, model\n","                )\n","            for goal_k in results_val:\n","                for metric_k in results_val[goal_k]:\n","                    results_history_val[goal_k][metric_k].append(np.average(\n","                        results_val[goal_k][metric_k],\n","                        weights=results_val[goal_k][\"weights\"],\n","                    ))\n","            # Print the results\n","            outer.update(1)\n","\n","            out_string = (\n","                f\" {epoch:5d} \"\n","                f\"|| {results_history['clf']['loss'][-1]:6.4f} \"\n","                f\"| {results_history_val['clf']['loss'][-1]:6.4f} \"\n","                f\"|| {results_history['dis']['loss'][-1]:6.4f} \"\n","                f\"| {results_history_val['dis']['loss'][-1]:6.4f} \"\n","                f\"|| {results_history['ovr']['loss'][-1]:6.4f} \"\n","                f\"| {results_history_val['ovr']['loss'][-1]:6.4f} \"\n","            )\n","            \n","            better_val_loss = results_history_val['ovr']['loss'][-1] < best_loss_val\n","            if better_val_loss:\n","                best_loss_val = results_history_val['ovr']['loss'][-1]\n","                torch.save(checkpoint, os.path.join(save_folder, f\"best_model.pth\"))\n","                early_stop_count = 0\n","                out_string += f\"<-- new best val loss\"\n","\n","            tqdm.write(out_string)\n","\n","            early_stop_count += 1\n","\n","    # Save final model\n","    torch.save(checkpoint, os.path.join(save_folder, f\"final_model.pth\"))\n","\n","    return results_history, results_history_running, results_history_val\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["def plot_results(\n","    results_history, results_history_running, results_history_val, save_folder\n","):\n","\n","    fig, axs = plt.subplots(3, 1, sharex=True, figsize=(9, 9), layout=\"constrained\")\n","\n","    # Coral\n","    axs[0].plot(\n","        *format_iters(results_history_running[\"dis\"][\"loss\"]),\n","        label=\"training\",\n","        linewidth=0.5,\n","    )\n","    axs[0].plot(results_history_val[\"dis\"][\"loss\"], label=\"validation\")\n","\n","    axs[0].set_ylim(bottom=0, top=max(results_history_val[\"dis\"][\"loss\"]))\n","    axs[0].grid(which=\"major\")\n","    axs[0].minorticks_on()\n","    axs[0].grid(which=\"minor\", alpha=0.2)\n","\n","    axs[0].set_title(\"CORAL Loss\")\n","    axs[0].legend()\n","\n","    # KLDiv\n","    axs[1].plot(\n","        *format_iters(results_history_running[\"clf\"][\"loss\"]),\n","        label=\"training\",\n","        linewidth=0.5,\n","    )\n","    axs[1].plot(results_history_val[\"clf\"][\"loss\"], label=\"validation\")\n","\n","    axs[1].set_ylim(bottom=0, top=max(results_history_val[\"clf\"][\"loss\"]))\n","    axs[1].grid(which=\"major\")\n","    axs[1].minorticks_on()\n","    axs[1].grid(which=\"minor\", alpha=0.2)\n","\n","    axs[1].set_title(\"KL-Divergence Loss\")\n","    axs[1].legend()\n","\n","    # Overall\n","    axs[2].plot(\n","        *format_iters(results_history_running[\"ovr\"][\"loss\"]),\n","        label=\"training\",\n","        linewidth=0.5,\n","    )\n","    axs[2].plot(results_history_val[\"ovr\"][\"loss\"], label=\"validation\")\n","\n","    axs[2].set_ylim(bottom=0, top=max(results_history_val[\"ovr\"][\"loss\"]))\n","    axs[2].grid(which=\"major\")\n","    axs[2].minorticks_on()\n","    axs[2].grid(which=\"minor\", alpha=0.2)\n","\n","    axs[2].set_title(\"Overall Loss\")\n","    axs[2].legend()\n","\n","    plt.savefig(os.path.join(save_folder, \"adv_train.png\"))\n","\n","    plt.show(block=False)\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# st_sample_id_l = [SAMPLE_ID_N]\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["if data_params[\"train_using_all_st_samples\"]:\n","    print(f\"Adversarial training for all ST slides\")\n","    save_folder = advtrain_folder\n","\n","    model = CORAL(\n","        sc_mix_d[\"train\"].shape[1],\n","        ncls_source=lab_mix_d[\"train\"].shape[1],\n","        **model_params[\"coral_kwargs\"],\n","    )\n","    model.apply(initialize_weights)\n","    if train_params.get(\"pretraining\", False):\n","        best_pre_checkpoint = torch.load(\n","            os.path.join(pretrain_folder, f\"final_model.pth\")\n","        )\n","        model.load_state_dict(best_pre_checkpoint[\"model\"].state_dict())\n","    model.to(device)\n","\n","    model.advtraining()\n","\n","    train_adversarial_iters(\n","        model,\n","        save_folder,\n","        dataloader_source_train,\n","        dataloader_source_val,\n","        dataloader_target_train,\n","    )\n","\n","else:\n","    for sample_id in st_sample_id_l:\n","        print(f\"Adversarial training for ST slide {sample_id}: \")\n","\n","        save_folder = os.path.join(advtrain_folder, sample_id)\n","        if not os.path.isdir(save_folder):\n","            os.makedirs(save_folder)\n","\n","        model = CORAL(\n","            sc_mix_d[\"train\"].shape[1],\n","            ncls_source=lab_mix_d[\"train\"].shape[1],\n","            **model_params[\"coral_kwargs\"],\n","        )\n","        model.apply(initialize_weights)\n","\n","        if train_params[\"pretraining\"]:\n","            best_pre_checkpoint = torch.load(\n","                os.path.join(pretrain_folder, f\"final_model.pth\")\n","            )\n","            model.load_state_dict(best_pre_checkpoint[\"model\"].state_dict())\n","        model.to(device)\n","\n","        model.advtraining()\n","\n","        results = train_adversarial_iters(\n","            model,\n","            save_folder,\n","            dataloader_source_train,\n","            dataloader_source_val,\n","            dataloader_target_train_d[sample_id],\n","        )\n","        plot_results(*results, save_folder)\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["with open(os.path.join(model_folder, \"config.yml\"), \"w\") as f:\n","    yaml.safe_dump(config, f)\n","\n"]},{"cell_type":"markdown","metadata":{},"source":[" ## Evaluation of latent space"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# from sklearn.decomposition import PCA\n","# from sklearn import model_selection\n","# from sklearn.ensemble import RandomForestClassifier\n","\n","\n","# for sample_id in st_sample_id_l:\n","#     best_checkpoint = torch.load(\n","#         os.path.join(advtrain_folder, sample_id, f\"final_model.pth\")\n","#     )\n","#     model = best_checkpoint[\"model\"]\n","#     model.to(device)\n","\n","#     model.eval()\n","#     model.target_inference()\n","\n","#     with torch.no_grad():\n","#         source_emb = model.source_encoder(torch.Tensor(sc_mix_train_s).to(device))\n","#         target_emb = model.target_encoder(\n","#             torch.Tensor(mat_sp_test_s_d[sample_id]).to(device)\n","#         )\n","\n","#         y_dis = torch.cat(\n","#             [\n","#                 torch.zeros(source_emb.shape[0], device=device, dtype=torch.long),\n","#                 torch.ones(target_emb.shape[0], device=device, dtype=torch.long),\n","#             ]\n","#         )\n","\n","#         emb = torch.cat([source_emb, target_emb])\n","\n","#         emb = emb.detach().cpu().numpy()\n","#         y_dis = y_dis.detach().cpu().numpy()\n","\n","#     (emb_train, emb_test, y_dis_train, y_dis_test,) = model_selection.train_test_split(\n","#         emb,\n","#         y_dis,\n","#         test_size=0.2,\n","#         random_state=225,\n","#         stratify=y_dis,\n","#     )\n","\n","#     pca = PCA(n_components=50)\n","#     pca.fit(emb_train)\n","\n","#     emb_train_50 = pca.transform(emb_train)\n","#     emb_test_50 = pca.transform(emb_test)\n","\n","#     clf = RandomForestClassifier(random_state=145, n_jobs=-1)\n","#     clf.fit(emb_train_50, y_dis_train)\n","#     accu_train = clf.score(emb_train_50, y_dis_train)\n","#     accu_test = clf.score(emb_test_50, y_dis_test)\n","#     class_proportions = np.mean(y_dis)\n","\n","#     print(\n","#         \"Training accuracy: {}, Test accuracy: {}, Class proportions: {}\".format(\n","#             accu_train, accu_test, class_proportions\n","#         )\n","#     )\n","\n"]},{"cell_type":"markdown","metadata":{},"source":["  # 4. Predict cell fraction of spots and visualization"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# pred_sp_d, pred_sp_noda_d = {}, {}\n","# if TRAIN_USING_ALL_ST_SAMPLES:\n","#     best_checkpoint = torch.load(os.path.join(advtrain_folder, f\"final_model.pth\"))\n","#     model = best_checkpoint[\"model\"]\n","#     model.to(device)\n","\n","#     model.eval()\n","#     model.target_inference()\n","#     with torch.no_grad():\n","#         for sample_id in st_sample_id_l:\n","#             pred_sp_d[sample_id] = (\n","#                 torch.exp(\n","#                     model(torch.Tensor(mat_sp_test_s_d[sample_id]).to(device))\n","#                 )\n","#                 .detach()\n","#                 .cpu()\n","#                 .numpy()\n","#             )\n","\n","# else:\n","#     for sample_id in st_sample_id_l:\n","#         best_checkpoint = torch.load(\n","#             os.path.join(advtrain_folder, sample_id, f\"final_model.pth\")\n","#         )\n","#         model = best_checkpoint[\"model\"]\n","#         model.to(device)\n","\n","#         model.eval()\n","#         model.target_inference()\n","\n","#         with torch.no_grad():\n","#             pred_sp_d[sample_id] = (\n","#                 torch.exp(\n","#                     model(torch.Tensor(mat_sp_test_s_d[sample_id]).to(device))\n","#                 )\n","#                 .detach()\n","#                 .cpu()\n","#                 .numpy()\n","#             )\n","\n","\n","# best_checkpoint = torch.load(os.path.join(pretrain_folder, f\"best_model.pth\"))\n","# model = best_checkpoint[\"model\"]\n","# model.to(device)\n","\n","# model.eval()\n","# model.set_encoder(\"source\")\n","\n","# with torch.no_grad():\n","#     for sample_id in st_sample_id_l:\n","#         pred_sp_noda_d[sample_id] = (\n","#             torch.exp(model(torch.Tensor(mat_sp_test_s_d[sample_id]).to(device)))\n","#             .detach()\n","#             .cpu()\n","#             .numpy()\n","#         )\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# adata_spatialLIBD = sc.read_h5ad(\n","#     os.path.join(PROCESSED_DATA_DIR, \"adata_spatialLIBD.h5ad\")\n","# )\n","\n","# adata_spatialLIBD_d = {}\n","# for sample_id in st_sample_id_l:\n","#     adata_spatialLIBD_d[sample_id] = adata_spatialLIBD[\n","#         adata_spatialLIBD.obs.sample_id == sample_id\n","#     ]\n","#     adata_spatialLIBD_d[sample_id].obsm[\"spatial\"] = (\n","#         adata_spatialLIBD_d[sample_id].obs[[\"X\", \"Y\"]].values\n","#     )\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# num_name_exN_l = []\n","# for k, v in sc_sub_dict.items():\n","#     if \"Ex\" in v:\n","#         num_name_exN_l.append((k, v, int(v.split(\"_\")[1])))\n","# num_name_exN_l.sort(key=lambda a: a[2])\n","# num_name_exN_l\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Ex_to_L_d = {\n","#     1: {5, 6},\n","#     2: {5},\n","#     3: {4, 5},\n","#     4: {6},\n","#     5: {5},\n","#     6: {4, 5, 6},\n","#     7: {4, 5, 6},\n","#     8: {5, 6},\n","#     9: {5, 6},\n","#     10: {2, 3, 4},\n","# }\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# numlist = [t[0] for t in num_name_exN_l]\n","# Ex_l = [t[2] for t in num_name_exN_l]\n","# num_to_ex_d = dict(zip(numlist, Ex_l))\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# def plot_cellfraction(visnum, adata, pred_sp, ax=None):\n","#     \"\"\"Plot predicted cell fraction for a given visnum\"\"\"\n","#     adata.obs[\"Pred_label\"] = pred_sp[:, visnum]\n","#     # vmin = 0\n","#     # vmax = np.amax(pred_sp)\n","\n","#     sc.pl.spatial(\n","#         adata,\n","#         img_key=\"hires\",\n","#         color=\"Pred_label\",\n","#         palette=\"Set1\",\n","#         size=1.5,\n","#         legend_loc=None,\n","#         title=f\"{sc_sub_dict[visnum]}\",\n","#         spot_size=100,\n","#         show=False,\n","#         # vmin=vmin,\n","#         # vmax=vmax,\n","#         ax=ax,\n","#     )\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# def plot_roc(visnum, adata, pred_sp, name, ax=None):\n","#     \"\"\"Plot ROC for a given visnum\"\"\"\n","\n","#     def layer_to_layer_number(x):\n","#         for char in x:\n","#             if char.isdigit():\n","#                 if int(char) in Ex_to_L_d[num_to_ex_d[visnum]]:\n","#                     return 1\n","#         return 0\n","\n","#     y_pred = pred_sp[:, visnum]\n","#     y_true = adata.obs[\"spatialLIBD\"].map(layer_to_layer_number).fillna(0)\n","#     # print(y_true)\n","#     # print(y_true.isna().sum())\n","#     RocCurveDisplay.from_predictions(y_true=y_true, y_pred=y_pred, name=name, ax=ax)\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# fig, ax = plt.subplots(nrows=1, ncols=1, figsize=(5, 5), constrained_layout=True)\n","\n","# sc.pl.spatial(\n","#     adata_spatialLIBD_d[SAMPLE_ID_N],\n","#     img_key=None,\n","#     color=\"spatialLIBD\",\n","#     palette=\"Accent_r\",\n","#     size=1.5,\n","#     title=SAMPLE_ID_N,\n","#     # legend_loc = 4,\n","#     spot_size=100,\n","#     show=False,\n","#     ax=ax,\n","# )\n","\n","# ax.axis(\"equal\")\n","# ax.set_xlabel(\"\")\n","# ax.set_ylabel(\"\")\n","\n","# fig.show()\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# fig, ax = plt.subplots(2, 5, figsize=(20, 8), constrained_layout=True)\n","\n","# for i, num in enumerate(numlist):\n","#     plot_cellfraction(\n","#         num, adata_spatialLIBD_d[SAMPLE_ID_N], pred_sp_d[SAMPLE_ID_N], ax.flat[i]\n","#     )\n","#     ax.flat[i].axis(\"equal\")\n","#     ax.flat[i].set_xlabel(\"\")\n","#     ax.flat[i].set_ylabel(\"\")\n","\n","# fig.show()\n","\n","# fig, ax = plt.subplots(\n","#     2, 5, figsize=(20, 8), constrained_layout=True, sharex=True, sharey=True\n","# )\n","\n","# for i, num in enumerate(numlist):\n","#     plot_roc(\n","#         num,\n","#         adata_spatialLIBD_d[SAMPLE_ID_N],\n","#         pred_sp_d[SAMPLE_ID_N],\n","#         \"ADDA\",\n","#         ax.flat[i],\n","#     )\n","#     plot_roc(\n","#         num,\n","#         adata_spatialLIBD_d[SAMPLE_ID_N],\n","#         pred_sp_noda_d[SAMPLE_ID_N],\n","#         \"NN_wo_da\",\n","#         ax.flat[i],\n","#     )\n","#     ax.flat[i].plot([0, 1], [0, 1], transform=ax.flat[i].transAxes, ls=\"--\", color=\"k\")\n","#     ax.flat[i].set_aspect(\"equal\")\n","#     ax.flat[i].set_xlim([0, 1])\n","#     ax.flat[i].set_ylim([0, 1])\n","\n","#     ax.flat[i].set_title(f\"{sc_sub_dict[num]}\")\n","\n","#     if i >= len(numlist) - 5:\n","#         ax.flat[i].set_xlabel(\"FPR\")\n","#     else:\n","#         ax.flat[i].set_xlabel(\"\")\n","#     if i % 5 == 0:\n","#         ax.flat[i].set_ylabel(\"TPR\")\n","#     else:\n","#         ax.flat[i].set_ylabel(\"\")\n","\n","# fig.show()\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# if TRAIN_USING_ALL_ST_SAMPLES:\n","#     best_checkpoint = torch.load(os.path.join(advtrain_folder, f\"final_model.pth\"))\n","# else:\n","#     best_checkpoint = torch.load(\n","#         os.path.join(advtrain_folder, SAMPLE_ID_N, f\"final_model.pth\")\n","#     )\n","\n","# model = best_checkpoint[\"model\"]\n","# model.to(device)\n","\n","# model.eval()\n","# model.set_encoder(\"source\")\n","\n","# with torch.no_grad():\n","#     pred_mix = (\n","#         torch.exp(model(torch.Tensor(sc_mix_test_s).to(device)))\n","#         .detach()\n","#         .cpu()\n","#         .numpy()\n","#     )\n","\n","# cell_type_nums = sc_sub_dict.keys()\n","# nrows = ceil(len(cell_type_nums) / 5)\n","\n","# line_kws = {\"color\": \"tab:orange\"}\n","# scatter_kws = {\"s\": 5}\n","\n","# props = dict(facecolor=\"w\", alpha=0.5)\n","\n","# fig, ax = plt.subplots(\n","#     nrows,\n","#     5,\n","#     figsize=(25, 5 * nrows),\n","#     constrained_layout=True,\n","#     sharex=False,\n","#     sharey=True,\n","# )\n","# for i, visnum in enumerate(cell_type_nums):\n","#     sns.regplot(\n","#         x=pred_mix[:, visnum],\n","#         y=lab_mix_test[:, visnum],\n","#         line_kws=line_kws,\n","#         scatter_kws=scatter_kws,\n","#         ax=ax.flat[i],\n","#     ).set_title(sc_sub_dict[visnum])\n","\n","#     ax.flat[i].set_aspect(\"equal\")\n","#     ax.flat[i].set_xlabel(\"Predicted Proportion\")\n","\n","#     if i % 5 == 0:\n","#         ax.flat[i].set_ylabel(\"True Proportion\")\n","#     else:\n","#         ax.flat[i].set_ylabel(\"\")\n","#     ax.flat[i].set_xlim([0, 1])\n","#     ax.flat[i].set_ylim([0, 1])\n","\n","#     textstr = (\n","#         f\"MSE: {mean_squared_error(pred_mix[:,visnum], lab_mix_test[:,visnum]):.5f}\"\n","#     )\n","\n","#     # place a text box in upper left in axes coords\n","#     ax.flat[i].text(\n","#         0.95,\n","#         0.05,\n","#         textstr,\n","#         transform=ax.flat[i].transAxes,\n","#         verticalalignment=\"bottom\",\n","#         horizontalalignment=\"right\",\n","#         bbox=props,\n","#     )\n","\n","# for i in range(len(cell_type_nums), nrows * 5):\n","#     ax.flat[i].axis(\"off\")\n","\n","# plt.show()\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]}],"metadata":{"kernelspec":{"display_name":"agreda","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.4"},"orig_nbformat":4,"vscode":{"interpreter":{"hash":"330b2d1c36bdd59efd1cb99466680f0cb310a0929e0186587128f5e2b14c88ce"}}},"nbformat":4,"nbformat_minor":2}
