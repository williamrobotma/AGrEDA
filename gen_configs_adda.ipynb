{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import itertools\n",
    "import os\n",
    "import yaml\n",
    "from copy import deepcopy\n",
    "\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "CONFIG_FNAME = \"standard_bnfix_adam_beta1_5_spotless_sc.yml\"\n",
    "MODEL_NAME = \"ADDA\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data_params:\n",
      "  all_genes: false\n",
      "  data_dir: data\n",
      "  dset: mouse_cortex\n",
      "  n_markers: 20\n",
      "  n_mix: 10\n",
      "  n_spots: 2000\n",
      "  samp_split: true\n",
      "  sample_id_n: '151673'\n",
      "  sc_id: GSE115746\n",
      "  scaler_name: standard\n",
      "  st_id: spotless_mouse_cortex\n",
      "  st_split: false\n",
      "lib_params:\n",
      "  manual_seed: 12865\n",
      "model_params:\n",
      "  adda_kwargs:\n",
      "    bn_momentum: 0.01\n",
      "    emb_dim: 64\n",
      "  model_version: standard_bnfix_adam_beta1_5_spotless_sc\n",
      "train_params:\n",
      "  adam_beta1: 0.5\n",
      "  alpha: 2\n",
      "  batch_size: 16\n",
      "  dis_loop_factor: 5\n",
      "  early_stop_crit: 100\n",
      "  early_stop_crit_adv: 200\n",
      "  enc_lr: 2.0e-05\n",
      "  epochs: 200\n",
      "  initial_train_epochs: 100\n",
      "  initial_train_lr: 0.0002\n",
      "  min_epochs: 40.0\n",
      "  min_epochs_adv: 80.0\n",
      "  pretraining: true\n",
      "\n"
     ]
    }
   ],
   "source": [
    "with open(os.path.join(\"configs\", MODEL_NAME, CONFIG_FNAME), \"r\") as f:\n",
    "    config = yaml.safe_load(f)\n",
    "print(yaml.safe_dump(config))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "config[\"data_params\"][\"all_genes\"] = False\n",
    "config[\"data_params\"][\"data_dir\"] = \"data\"\n",
    "config[\"data_params\"][\"dset\"] = \"dlpfc\"\n",
    "config[\"data_params\"][\"sc_id\"] = \"GSE144136\"\n",
    "config[\"data_params\"][\"st_id\"] = \"spatialLIBD\"\n",
    "config[\"data_params\"][\"st_split\"] = False\n",
    "config[\"data_params\"][\"samp_split\"] = True\n",
    "\n",
    "config[\"train_params\"][\"epochs\"] = 500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ## CellDART\n",
    "\n",
    "# # data_params\n",
    "# n_markers_l = [5, 10, 20, 40, 80]\n",
    "# n_mix_l =  [5, 8, 10, 15, 20]\n",
    "# n_spots_l = [5000, 10000, 20000, 50000, 100000, 200000]\n",
    "# scaler_name_l = [\"minmax\", \"standard\"]\n",
    "\n",
    "# # model_params\n",
    "# bn_momentum_l = [0.01, 0.1, 0.9, 0.99]\n",
    "\n",
    "\n",
    "# # train_params\n",
    "# alpha_l =  [0.1, 0.6, 1.0, 2.0]\n",
    "# alpha_lr_l = [1, 2, 5, 10]\n",
    "# batch_size_l = [256, 512, 1024]\n",
    "# lr_l =[0.01, 0.001, 0.0001]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "## ADDA\n",
    "\n",
    "# data_params\n",
    "data_params_lists = dict(\n",
    "    n_markers=[5, 10, 20, 40, 80],\n",
    "    n_mix=[5, 8, 10, 15, 20],\n",
    "    n_spots=[5000, 10000, 20000, 50000, 100000, 200000],\n",
    "    scaler_name=[\"standard\"],\n",
    ")\n",
    "\n",
    "# model_params\n",
    "model_params_lists = dict(\n",
    "    bn_momentum=[0.1, 0.01],\n",
    "    emb_dim=[32, 64, 128],\n",
    ")\n",
    "# train_params\n",
    "train_params_lists = dict(\n",
    "    adam_beta1=[0.5, 0.9],\n",
    "    alpha=[1, 2, 5],\n",
    "    batch_size=[512, 1024, 2048],\n",
    "    dis_loop_factor=[2, 5, 10],\n",
    "    enc_lr=[0.000002, 0.00002, 0.0002],\n",
    "    initial_train_lr=[0.0001, 0.0002, 0.001],\n",
    "    initial_train_epochs=[50, 100, 200],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1312200"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total_configs = 1\n",
    "for value in data_params_lists.values():\n",
    "    total_configs *= len(value)\n",
    "for value in model_params_lists.values():\n",
    "    total_configs *= len(value)\n",
    "for value in train_params_lists.values():\n",
    "    total_configs *= len(value)\n",
    "total_configs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'data_params': {'all_genes': False,\n",
       "  'data_dir': 'data',\n",
       "  'dset': 'dlpfc',\n",
       "  'n_markers': 20,\n",
       "  'n_mix': 10,\n",
       "  'n_spots': 2000,\n",
       "  'sample_id_n': '151673',\n",
       "  'scaler_name': 'standard',\n",
       "  'sc_id': 'GSE144136',\n",
       "  'st_id': 'spatialLIBD',\n",
       "  'st_split': False,\n",
       "  'samp_split': True},\n",
       " 'model_params': {'adda_kwargs': {'bn_momentum': 0.01, 'emb_dim': 64},\n",
       "  'model_version': 'standard_bnfix_adam_beta1_5_spotless_sc'},\n",
       " 'lib_params': {'manual_seed': 12865},\n",
       " 'train_params': {'adam_beta1': 0.5,\n",
       "  'alpha': 2,\n",
       "  'batch_size': 16,\n",
       "  'dis_loop_factor': 5,\n",
       "  'early_stop_crit': 100,\n",
       "  'early_stop_crit_adv': 200,\n",
       "  'enc_lr': 2e-05,\n",
       "  'epochs': 500,\n",
       "  'initial_train_lr': 0.0002,\n",
       "  'initial_train_epochs': 100,\n",
       "  'min_epochs': 40.0,\n",
       "  'min_epochs_adv': 80.0,\n",
       "  'pretraining': True}}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "rng = np.random.default_rng(3853)\n",
    "\n",
    "yes_samples = set(rng.choice(total_configs, size=1000, replace=False))\n",
    "\n",
    "\n",
    "data_params_l = []\n",
    "# for n_markers, n_mix, n_spots, scaler_name in itertools.product(\n",
    "#     n_markers_l, n_mix_l, n_spots_l, scaler_name_l\n",
    "# ):\n",
    "#     data_params_l.append(\n",
    "#         dict(n_markers=n_markers, n_mix=n_mix, n_spots=n_spots, scaler_name=scaler_name)\n",
    "#     )\n",
    "for kv_tuples in itertools.product(*[[(k,v) for v in vlist] for k, vlist in data_params_lists.items()]):\n",
    "    data_params_l.append(dict(kv_tuples))\n",
    "\n",
    "model_params_l = []\n",
    "# for k, v_list in model_params_lists.items():\n",
    "#     if len(model_params_l) == 0:\n",
    "#         for v in v_list:\n",
    "#             model_params_l.append({k: v})\n",
    "#     else:\n",
    "#         new_model_params_l = []\n",
    "#         for v in v_list:\n",
    "#             for d in model_params_l:\n",
    "for kv_tuples in itertools.product(*[[(k,v) for v in vlist] for k, vlist in model_params_lists.items()]):\n",
    "    model_params_l.append(dict(kv_tuples))\n",
    "\n",
    "train_params_l = []\n",
    "# for alpha, alpha_lr, batch_size, lr in itertools.product(\n",
    "#     adam_beta1_l,\n",
    "#     alpha_l,\n",
    "#     batch_size_l,\n",
    "#     dis_loop_factor_l,\n",
    "#     enc_lr_l,\n",
    "#     initial_train_lr,\n",
    "#     initial_train_epochs,\n",
    "# ):\n",
    "#     train_params_l.append(dict(alpha=alpha, alpha_lr=alpha_lr, batch_size=batch_size, lr=lr))\n",
    "for kv_tuples in itertools.product(*[[(k,v) for v in vlist] for k, vlist in train_params_lists.items()]):\n",
    "    train_params_l.append(dict(kv_tuples))\n",
    "\n",
    "if not os.path.exists(os.path.join(\"configs/generated\", MODEL_NAME)):\n",
    "    os.makedirs(os.path.join(\"configs/generated\", MODEL_NAME))\n",
    "for i, (data_params, model_params, train_params) in enumerate(\n",
    "    itertools.product(data_params_l, model_params_l, train_params_l)\n",
    "):\n",
    "    if i not in yes_samples:\n",
    "        continue\n",
    "\n",
    "    new_config = deepcopy(config)\n",
    "    new_config[\"data_params\"].update(data_params)\n",
    "    new_config[\"model_params\"][\"adda_kwargs\"].update(model_params)\n",
    "    new_config[\"train_params\"].update(train_params)\n",
    "\n",
    "    new_config[\"lib_params\"][\"manual_seed\"] = int(rng.integers(0, 2**32))\n",
    "\n",
    "    version = f\"gen_v1_perm_{i}\"\n",
    "    new_config[\"model_params\"][\"model_version\"] = version\n",
    "\n",
    "    with open(os.path.join(\"configs/generated\", MODEL_NAME, f\"{version}.yml\"), \"w\") as f:\n",
    "        yaml.safe_dump(new_config, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'data_params': {'all_genes': False,\n",
       "  'data_dir': 'data',\n",
       "  'dset': 'dlpfc',\n",
       "  'n_markers': 80,\n",
       "  'n_mix': 20,\n",
       "  'n_spots': 200000,\n",
       "  'sample_id_n': '151673',\n",
       "  'scaler_name': 'standard',\n",
       "  'sc_id': 'GSE144136',\n",
       "  'st_id': 'spatialLIBD',\n",
       "  'st_split': False,\n",
       "  'samp_split': True},\n",
       " 'model_params': {'adda_kwargs': {'bn_momentum': 0.01, 'emb_dim': 128},\n",
       "  'model_version': 'gen_v1_perm_1312012'},\n",
       " 'lib_params': {'manual_seed': 1378592176},\n",
       " 'train_params': {'adam_beta1': 0.9,\n",
       "  'alpha': 5,\n",
       "  'batch_size': 512,\n",
       "  'dis_loop_factor': 10,\n",
       "  'early_stop_crit': 100,\n",
       "  'early_stop_crit_adv': 200,\n",
       "  'enc_lr': 2e-06,\n",
       "  'epochs': 500,\n",
       "  'initial_train_lr': 0.0001,\n",
       "  'initial_train_epochs': 100,\n",
       "  'min_epochs': 40.0,\n",
       "  'min_epochs_adv': 80.0,\n",
       "  'pretraining': True}}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_config\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "lines = [\n",
    "    os.path.basename(name)\n",
    "    for name in glob.glob(os.path.join(\"configs/generated\", MODEL_NAME, \"*.yml\"))\n",
    "]\n",
    "with open(\n",
    "    os.path.join(\"configs/generated\", MODEL_NAME, \"a_list.txt\"),\n",
    "    mode=\"wt\",\n",
    "    encoding=\"utf-8\",\n",
    ") as myfile:\n",
    "    myfile.write(\"\\n\".join(lines))\n",
    "    myfile.write(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "agreda",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
