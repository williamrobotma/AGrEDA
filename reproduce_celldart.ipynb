{"cells":[{"cell_type":"markdown","metadata":{},"source":[" # ADDA for ST"]},{"cell_type":"code","execution_count":1,"metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["/tmp/ipykernel_1186280/2753113568.py:7: TqdmExperimentalWarning: Using `tqdm.autonotebook.tqdm` in notebook mode. Use `tqdm.tqdm` instead to force console mode (e.g. in jupyter console)\n","  from tqdm.autonotebook import tqdm\n"]}],"source":["import os\n","import datetime\n","from itertools import chain\n","from copy import deepcopy\n","import warnings\n","\n","from tqdm.autonotebook import tqdm\n","\n","import h5py\n","import pickle\n","import numpy as np\n","\n","import torch\n","from torch import nn\n","\n","from src.da_models.adda import ADDAST\n","from src.da_models.datasets import SpotDataset\n","from src.da_models.utils import set_requires_grad\n","\n","# datetime object containing current date and time\n","script_start_time = datetime.datetime.now().strftime(\"%Y-%m-%d_%Hh%Mm%S\")\n"]},{"cell_type":"code","execution_count":2,"metadata":{},"outputs":[],"source":["device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","if device == \"cpu\":\n","    warnings.warn(\n","        'Using CPU', \n","        stacklevel=2)"]},{"cell_type":"code","execution_count":3,"metadata":{},"outputs":[],"source":["\n","NUM_MARKERS = 20\n","N_MIX = 8\n","N_SPOTS = 20000\n","TRAIN_USING_ALL_ST_SAMPLES = False\n","\n","SAMPLE_ID_N = \"151673\"\n","\n","BATCH_SIZE = 512\n","NUM_WORKERS = 4\n","INITIAL_TRAIN_EPOCHS = 10\n","\n","EARLY_STOP_CRIT = 100\n","MIN_EPOCHS = INITIAL_TRAIN_EPOCHS\n","\n","\n","EARLY_STOP_CRIT_ADV = 10\n","MIN_EPOCHS_ADV = 10\n","\n","SPATIALLIBD_DIR = \"./data/spatialLIBD\"\n","SC_DLPFC_PATH = \"./data/sc_dlpfc/adata_sc_dlpfc.h5ad\"\n","\n","PROCESSED_DATA_DIR = \"./data/preprocessed\"\n","\n","MODEL_NAME = \"CellDART\"\n"]},{"cell_type":"code","execution_count":4,"metadata":{},"outputs":[],"source":["model_folder = os.path.join(\"model\", MODEL_NAME, script_start_time)\n","\n","model_folder = os.path.join(\"model\", MODEL_NAME, \"TESTING\")\n","\n","if not os.path.isdir(model_folder):\n","    os.makedirs(model_folder)\n","    print(model_folder)\n"]},{"cell_type":"markdown","metadata":{},"source":[" # Data load\n"]},{"cell_type":"code","execution_count":5,"metadata":{},"outputs":[],"source":["# Load spatial data\n","mat_sp_test_s_d = {}\n","with h5py.File(os.path.join(PROCESSED_DATA_DIR, \"mat_sp_test_s_d.hdf5\"), \"r\") as f:\n","    for sample_id in f:\n","        mat_sp_test_s_d[sample_id] = f[sample_id][()]\n","\n","if TRAIN_USING_ALL_ST_SAMPLES:\n","    with h5py.File(os.path.join(PROCESSED_DATA_DIR, \"mat_sp_train_s.hdf5\"), \"r\") as f:\n","        mat_sp_train_s = f[\"all\"][()]\n","else:\n","    mat_sp_train_s_d = mat_sp_test_s_d\n","\n","# Load sc data\n","with h5py.File(os.path.join(PROCESSED_DATA_DIR, \"sc.hdf5\"), \"r\") as f:\n","    sc_mix_train_s = f[\"X/train\"][()]\n","    sc_mix_val_s = f[\"X/val\"][()]\n","    sc_mix_test_s = f[\"X/test\"][()]\n","\n","    lab_mix_train = f[\"y/train\"][()]\n","    lab_mix_val = f[\"y/val\"][()]\n","    lab_mix_test = f[\"y/test\"][()]\n","\n","# Load helper dicts / lists\n","with open(os.path.join(PROCESSED_DATA_DIR, \"sc_sub_dict.pkl\"), \"rb\") as f:\n","    sc_sub_dict = pickle.load(f)\n","\n","with open(os.path.join(PROCESSED_DATA_DIR, \"sc_sub_dict2.pkl\"), \"rb\") as f:\n","    sc_sub_dict2 = pickle.load(f)\n","\n","with open(os.path.join(PROCESSED_DATA_DIR, \"st_sample_id_l.pkl\"), \"rb\") as f:\n","    st_sample_id_l = pickle.load(f)\n"]},{"cell_type":"markdown","metadata":{},"source":[" # Training: Adversarial domain adaptation for cell fraction estimation"]},{"cell_type":"markdown","metadata":{},"source":[" ## Prepare dataloaders"]},{"cell_type":"code","execution_count":6,"metadata":{},"outputs":[],"source":["### source dataloaders\n","source_train_set = SpotDataset(deepcopy(sc_mix_train_s), deepcopy(lab_mix_train))\n","source_val_set = SpotDataset(deepcopy(sc_mix_val_s), deepcopy(lab_mix_val))\n","source_test_set = SpotDataset(deepcopy(sc_mix_test_s), deepcopy(lab_mix_test))\n","\n","dataloader_source_train = torch.utils.data.DataLoader(\n","    source_train_set,\n","    batch_size=BATCH_SIZE,\n","    shuffle=True,\n","    num_workers=NUM_WORKERS,\n","    pin_memory=True,\n",")\n","dataloader_source_val = torch.utils.data.DataLoader(\n","    source_val_set,\n","    batch_size=BATCH_SIZE,\n","    shuffle=False,\n","    num_workers=NUM_WORKERS,\n","    pin_memory=False,\n",")\n","dataloader_source_test = torch.utils.data.DataLoader(\n","    source_test_set,\n","    batch_size=BATCH_SIZE,\n","    shuffle=False,\n","    num_workers=NUM_WORKERS,\n","    pin_memory=False,\n",")\n","\n","### target dataloaders\n","target_test_set_d = {}\n","for sample_id in st_sample_id_l:\n","    target_test_set_d[sample_id] = SpotDataset(deepcopy(mat_sp_test_s_d[sample_id]))\n","\n","dataloader_target_test_d = {}\n","for sample_id in st_sample_id_l:\n","    dataloader_target_test_d[sample_id] = torch.utils.data.DataLoader(\n","        target_test_set_d[sample_id],\n","        batch_size=BATCH_SIZE,\n","        shuffle=False,\n","        num_workers=NUM_WORKERS,\n","        pin_memory=False,\n","    )\n","\n","if TRAIN_USING_ALL_ST_SAMPLES:\n","    target_train_set = SpotDataset(deepcopy(mat_sp_train_s))\n","    dataloader_target_train = torch.utils.data.DataLoader(\n","        target_train_set,\n","        batch_size=BATCH_SIZE,\n","        shuffle=True,\n","        num_workers=NUM_WORKERS,\n","        pin_memory=True,\n","    )\n","else:\n","    target_train_set_d = {}\n","    dataloader_target_train_d = {}\n","    for sample_id in st_sample_id_l:\n","        target_train_set_d[sample_id] = SpotDataset(\n","            deepcopy(mat_sp_test_s_d[sample_id])\n","        )\n","        dataloader_target_train_d[sample_id] = torch.utils.data.DataLoader(\n","            target_train_set_d[sample_id],\n","            batch_size=BATCH_SIZE,\n","            shuffle=True,\n","            num_workers=NUM_WORKERS,\n","            pin_memory=True,\n","        )\n"]},{"cell_type":"markdown","metadata":{},"source":[" ## Define Model"]},{"cell_type":"code","execution_count":7,"metadata":{},"outputs":[{"data":{"text/plain":["ADDAST(\n","  (source_encoder): MLPEncoder(\n","    (encoder): Sequential(\n","      (0): Linear(in_features=367, out_features=1024, bias=True)\n","      (1): BatchNorm1d(1024, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n","      (2): ELU(alpha=1.0)\n","      (3): Linear(in_features=1024, out_features=64, bias=True)\n","      (4): BatchNorm1d(64, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n","      (5): ELU(alpha=1.0)\n","    )\n","  )\n","  (target_encoder): MLPEncoder(\n","    (encoder): Sequential(\n","      (0): Linear(in_features=367, out_features=1024, bias=True)\n","      (1): BatchNorm1d(1024, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n","      (2): ELU(alpha=1.0)\n","      (3): Linear(in_features=1024, out_features=64, bias=True)\n","      (4): BatchNorm1d(64, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n","      (5): ELU(alpha=1.0)\n","    )\n","  )\n","  (clf): Predictor(\n","    (head): Sequential(\n","      (0): Linear(in_features=64, out_features=33, bias=True)\n","      (1): LogSoftmax(dim=1)\n","    )\n","  )\n","  (dis): Discriminator(\n","    (head): Sequential(\n","      (0): Linear(in_features=64, out_features=32, bias=True)\n","      (1): BatchNorm1d(32, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n","      (2): ELU(alpha=1.0)\n","      (3): Dropout(p=0.5, inplace=False)\n","      (4): Linear(in_features=32, out_features=2, bias=True)\n","    )\n","  )\n",")"]},"execution_count":7,"metadata":{},"output_type":"execute_result"}],"source":["model = ADDAST(sc_mix_train_s.shape[1], emb_dim=64, ncls_source=lab_mix_train.shape[1])\n","\n","## CellDART uses just one encoder!\n","model.target_encoder = model.source_encoder\n","model.to(device)\n"]},{"cell_type":"markdown","metadata":{},"source":[" ## Pretrain"]},{"cell_type":"code","execution_count":8,"metadata":{},"outputs":[],"source":["pretrain_folder = os.path.join(model_folder, \"pretrain\")\n","\n","if not os.path.isdir(pretrain_folder):\n","    os.makedirs(pretrain_folder)\n"]},{"cell_type":"code","execution_count":9,"metadata":{},"outputs":[],"source":["pre_optimizer = torch.optim.Adam(\n","    model.parameters(), lr=0.001, betas=(0.9, 0.999), eps=1e-07\n",")\n","\n","criterion_clf = nn.KLDivLoss(reduction=\"batchmean\")\n"]},{"cell_type":"code","execution_count":10,"metadata":{},"outputs":[],"source":["def model_loss(x, y_true, model):\n","    x = x.to(torch.float32).to(device)\n","    y_true = y_true.to(torch.float32).to(device)\n","\n","    y_pred = model(x)\n","\n","    loss = criterion_clf(y_pred, y_true)\n","\n","    return loss\n","\n","\n","def compute_acc(dataloader, model):\n","    loss_running = []\n","    mean_weights = []\n","    model.eval()\n","    with torch.no_grad():\n","        for _, batch in enumerate(dataloader):\n","\n","            loss = model_loss(*batch, model)\n","\n","            loss_running.append(loss.item())\n","\n","            # we will weight average by batch size later\n","            mean_weights.append(len(batch))\n","\n","    return np.average(loss_running, weights=mean_weights)\n"]},{"cell_type":"code","execution_count":11,"metadata":{},"outputs":[],"source":["model.pretraining()\n"]},{"cell_type":"code","execution_count":12,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Start pretrain...\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"deed9a8968f24e83bb78b262a2d453e4","version_major":2,"version_minor":0},"text/plain":["Epochs:   0%|          | 0/10 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"9bc647932e474bb5a9aa73ec4786dd06","version_major":2,"version_minor":0},"text/plain":["Batch:   0%|          | 0/40 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["epoch: 0 train loss: 1.246527 validation loss: 0.991463 <-- new best val loss\n","epoch: 1 train loss: 0.894556 validation loss: 0.79241 <-- new best val loss\n","epoch: 2 train loss: 0.709414 validation loss: 0.690445 <-- new best val loss\n","epoch: 3 train loss: 0.621515 validation loss: 0.661922 <-- new best val loss\n","epoch: 4 train loss: 0.584557 validation loss: 0.65897 <-- new best val loss\n","epoch: 5 train loss: 0.561804 validation loss: 0.644848 <-- new best val loss\n","epoch: 6 train loss: 0.542548 validation loss: 0.642356 <-- new best val loss\n","epoch: 7 train loss: 0.527927 validation loss: 0.640265 <-- new best val loss\n","epoch: 8 train loss: 0.512742 validation loss: 0.630194 <-- new best val loss\n","epoch: 9 train loss: 0.500608 validation loss: 0.665679 \n"]}],"source":["# Initialize lists to store loss and accuracy values\n","loss_history = []\n","loss_history_val = []\n","\n","loss_history_running = []\n","\n","# Early Stopping\n","best_loss_val = np.inf\n","early_stop_count = 0\n","\n","# Train\n","print(\"Start pretrain...\")\n","outer = tqdm(total=INITIAL_TRAIN_EPOCHS, desc=\"Epochs\", position=0)\n","inner = tqdm(total=len(dataloader_source_train), desc=f\"Batch\", position=1)\n","\n","checkpoint = {\n","    \"epoch\": -1,\n","    \"model\": model,\n","    \"optimizer\": pre_optimizer,\n","}\n","for epoch in range(INITIAL_TRAIN_EPOCHS):\n","    checkpoint[\"epoch\"] = epoch\n","\n","    # Train mode\n","    model.train()\n","    loss_running = []\n","    mean_weights = []\n","\n","    inner.refresh()  # force print final state\n","    inner.reset()  # reuse bar\n","    for _, batch in enumerate(dataloader_source_train):\n","\n","        pre_optimizer.zero_grad()\n","        loss = model_loss(*batch, model)\n","        loss_running.append(loss.item())\n","        mean_weights.append(len(batch))  # we will weight average by batch size later\n","\n","        loss.backward()\n","        pre_optimizer.step()\n","\n","        inner.update(1)\n","\n","    loss_history.append(np.average(loss_running, weights=mean_weights))\n","    loss_history_running.append(loss_running)\n","\n","    # Evaluate mode\n","    model.eval()\n","    with torch.no_grad():\n","        curr_loss_val = compute_acc(dataloader_source_val, model)\n","        loss_history_val.append(curr_loss_val)\n","\n","    # Print the results\n","    outer.update(1)\n","    print(\n","        \"epoch:\",\n","        epoch,\n","        \"train loss:\",\n","        round(loss_history[-1], 6),\n","        \"validation loss:\",\n","        round(loss_history_val[-1], 6),\n","        end=\" \",\n","    )\n","\n","    # Save the best weights\n","    if curr_loss_val < best_loss_val:\n","        best_loss_val = curr_loss_val\n","        torch.save(checkpoint, os.path.join(pretrain_folder, f\"best_model.pth\"))\n","        early_stop_count = 0\n","\n","        print(\"<-- new best val loss\")\n","    else:\n","        print(\"\")\n","\n","    # Save checkpoint every 10\n","    if epoch % 10 == 0 or epoch >= INITIAL_TRAIN_EPOCHS - 1:\n","        torch.save(checkpoint, os.path.join(pretrain_folder, f\"checkpt{epoch}.pth\"))\n","\n","    # check to see if validation loss has plateau'd\n","    if early_stop_count >= EARLY_STOP_CRIT and epoch >= MIN_EPOCHS - 1:\n","        print(f\"Validation loss plateaued after {early_stop_count} at epoch {epoch}\")\n","        torch.save(checkpoint, os.path.join(pretrain_folder, f\"earlystop{epoch}.pth\"))\n","        break\n","\n","    early_stop_count += 1\n","\n","\n","# Save final model\n","torch.save(checkpoint, os.path.join(pretrain_folder, f\"final_model.pth\"))\n"]},{"cell_type":"markdown","metadata":{},"source":[" ## Adversarial Adaptation"]},{"cell_type":"code","execution_count":13,"metadata":{},"outputs":[],"source":["N_ITER = 3000\n","EPOCHS = 1000\n","ALPHA_LR = 5\n","ALPHA = 1 / 0.6\n"]},{"cell_type":"code","execution_count":14,"metadata":{},"outputs":[],"source":["advtrain_folder = os.path.join(model_folder, \"advtrain\")\n","\n","if not os.path.isdir(advtrain_folder):\n","    os.makedirs(advtrain_folder)\n"]},{"cell_type":"code","execution_count":15,"metadata":{},"outputs":[],"source":["def batch_generator(data, batch_size):\n","    \"\"\"Generate batches of data.\n","    Given a list of numpy data, it iterates over the list and returns batches of\n","    the same size\n","    This\n","    \"\"\"\n","    all_examples_indices = len(data[0])\n","    while True:\n","        mini_batch_indices = np.random.choice(\n","            all_examples_indices, size=batch_size, replace=False\n","        )\n","        tbr = [k[mini_batch_indices] for k in data]\n","        yield tbr\n"]},{"cell_type":"code","execution_count":16,"metadata":{},"outputs":[],"source":["criterion_dis = nn.CrossEntropyLoss()\n","\n","\n","def discrim_loss_accu(x, y_dis, model):\n","    x = x.to(torch.float32).to(device)\n","\n","    emb = model.source_encoder(x)\n","    y_pred = model.dis(emb)\n","\n","    loss = criterion_dis(y_pred, y_dis)\n","\n","    accu = torch.mean(\n","        (torch.flatten(torch.argmax(y_pred, dim=1)) == y_dis).to(torch.float32)\n","    ).cpu()\n","\n","    return loss, accu\n","\n","\n","def compute_acc_dis(dataloader_source, dataloader_target, model):\n","    len_target = len(dataloader_target)\n","    len_source = len(dataloader_source)\n","\n","    loss_running = []\n","    accu_running = []\n","    mean_weights = []\n","    model.eval()\n","    model.source_encoder.eval()\n","    model.dis.eval()\n","    with torch.no_grad():\n","        for y_val, dl in zip([1, 0], [dataloader_target, dataloader_source]):\n","            for _, (x, _) in enumerate(dl):\n","\n","                y_dis = torch.full(\n","                    (x.shape[0],), y_val, device=device, dtype=torch.long\n","                )\n","\n","                loss, accu = discrim_loss_accu(x, y_dis, model)\n","\n","                accu_running.append(accu)\n","                loss_running.append(loss.item())\n","\n","                # we will weight average by batch size later\n","                mean_weights.append(len(x))\n","\n","    return (\n","        np.average(loss_running, weights=mean_weights),\n","        np.average(accu_running, weights=mean_weights),\n","    )\n"]},{"cell_type":"code","execution_count":17,"metadata":{},"outputs":[],"source":["def train_adversarial(\n","    model,\n","    save_folder,\n","    sc_mix_train_s,\n","    lab_mix_train,\n","    mat_sp_train_s,\n","    dataloader_source_train_eval,\n","    dataloader_target_train_eval,\n","):\n","\n","    model.to(device)\n","    model.advtraining()\n","    model.set_encoder(\"source\")\n","\n","    S_batches = batch_generator(\n","        [sc_mix_train_s.copy(), lab_mix_train.copy()], BATCH_SIZE\n","    )\n","    T_batches = batch_generator(\n","        [mat_sp_train_s.copy(), np.ones(shape=(len(mat_sp_train_s), 2))], BATCH_SIZE\n","    )\n","\n","    enc_optimizer = torch.optim.Adam(\n","        chain(\n","            model.source_encoder.parameters(),\n","            model.dis.parameters(),\n","            model.clf.parameters(),\n","        ),\n","        lr=0.001,\n","        betas=(0.9, 0.999),\n","        eps=1e-07,\n","    )\n","\n","    dis_optimizer = torch.optim.Adam(\n","        chain(model.source_encoder.parameters(), model.dis.parameters()),\n","        lr=ALPHA_LR * 0.001,\n","        betas=(0.9, 0.999),\n","        eps=1e-07,\n","    )\n","\n","    # Initialize lists to store loss and accuracy values\n","    loss_history_running = []\n","\n","    # Train\n","    print(\"Start adversarial training...\")\n","    outer = tqdm(total=N_ITER, desc=\"Iterations\", position=0)\n","\n","    checkpoint = {\n","        \"epoch\": -1,\n","        \"model\": model,\n","        \"dis_optimizer\": dis_optimizer,\n","        \"enc_optimizer\": enc_optimizer,\n","    }\n","    for iters in range(N_ITER):\n","        checkpoint[\"epoch\"] = iters\n","\n","        model.train()\n","        model.dis.train()\n","        model.clf.train()\n","        model.source_encoder.train()\n","\n","        x_source, y_true = next(S_batches)\n","        x_target, _ = next(T_batches)\n","\n","        ## Train encoder\n","        set_requires_grad(model.source_encoder, True)\n","        set_requires_grad(model.clf, True)\n","        set_requires_grad(model.dis, True)\n","\n","        # save discriminator weights\n","        dis_weights = deepcopy(model.dis.state_dict())\n","        new_dis_weights = {}\n","        for k in dis_weights:\n","            if \"num_batches_tracked\" not in k:\n","                new_dis_weights[k] = dis_weights[k]\n","\n","        dis_weights = new_dis_weights\n","\n","        x_source, x_target, y_true, = (\n","            torch.Tensor(x_source),\n","            torch.Tensor(x_target),\n","            torch.Tensor(y_true),\n","        )\n","        x_source, x_target, y_true, = (\n","            x_source.to(device),\n","            x_target.to(device),\n","            y_true.to(device),\n","        )\n","\n","        x = torch.cat((x_source, x_target))\n","\n","        # save for discriminator later\n","        x_d = x.detach()\n","\n","        # y_dis is the REAL one\n","        y_dis = torch.cat(\n","            [\n","                torch.zeros(x_source.shape[0], device=device, dtype=torch.long),\n","                torch.ones(x_target.shape[0], device=device, dtype=torch.long),\n","            ]\n","        )\n","        y_dis_flipped = 1 - y_dis.detach()\n","\n","        emb = model.source_encoder(x).view(x.shape[0], -1)\n","\n","        y_dis_pred = model.dis(emb)\n","        y_clf_pred = model.clf(emb)\n","\n","        # we use flipped because we want to confuse discriminator\n","        loss_dis = criterion_dis(y_dis_pred, y_dis_flipped)\n","\n","        # Set true = predicted for target samples since we don't know what it is\n","        y_clf_true = torch.cat((y_true, y_clf_pred[-x_target.shape[0] :].detach()))\n","        # Loss fn does mean over all samples including target\n","        loss_clf = criterion_clf(y_clf_pred, y_clf_true)\n","\n","        # Scale back up loss so mean doesn't include target\n","        loss = (x.shape[0] / x_source.shape[0]) * loss_clf + ALPHA * loss_dis\n","\n","        # loss = loss_clf + ALPHA * loss_dis\n","\n","        enc_optimizer.zero_grad()\n","        loss.backward()\n","        enc_optimizer.step()\n","\n","        model.dis.load_state_dict(dis_weights, strict=False)\n","\n","        ## Train discriminator\n","        set_requires_grad(model.source_encoder, True)\n","        set_requires_grad(model.clf, True)\n","        set_requires_grad(model.dis, True)\n","\n","        # save encoder and clf weights\n","        source_encoder_weights = deepcopy(model.source_encoder.state_dict())\n","        clf_weights = deepcopy(model.clf.state_dict())\n","\n","        new_clf_weights = {}\n","        for k in clf_weights:\n","            if \"num_batches_tracked\" not in k:\n","                new_clf_weights[k] = clf_weights[k]\n","\n","        clf_weights = new_clf_weights\n","\n","        new_source_encoder_weights = {}\n","        for k in source_encoder_weights:\n","            if \"num_batches_tracked\" not in k:\n","                new_source_encoder_weights[k] = source_encoder_weights[k]\n","\n","        source_encoder_weights = new_source_encoder_weights\n","\n","        emb = model.source_encoder(x_d).view(x_d.shape[0], -1)\n","        y_pred = model.dis(emb)\n","\n","        # we use the real domain labels to train discriminator\n","        loss = criterion_dis(y_pred, y_dis)\n","\n","        dis_optimizer.zero_grad()\n","        loss.backward()\n","        dis_optimizer.step()\n","\n","        model.clf.load_state_dict(clf_weights, strict=False)\n","        model.source_encoder.load_state_dict(source_encoder_weights, strict=False)\n","\n","        # Save checkpoint every 100\n","        if iters % 100 == 99 or iters >= N_ITER - 1:\n","            torch.save(checkpoint, os.path.join(save_folder, f\"checkpt{iters}.pth\"))\n","\n","            model.eval()\n","            source_loss = compute_acc(dataloader_source_train_eval, model)\n","            _, dis_accu = compute_acc_dis(\n","                dataloader_source_train_eval, dataloader_target_train_eval, model\n","            )\n","\n","            # Print the results\n","            print(\n","                \"iter:\",\n","                iters,\n","                \"source loss:\",\n","                round(source_loss, 6),\n","                \"dis accu:\",\n","                round(dis_accu, 6),\n","            )\n","\n","        outer.update(1)\n","\n","    torch.save(checkpoint, os.path.join(save_folder, f\"final_model.pth\"))\n"]},{"cell_type":"code","execution_count":18,"metadata":{},"outputs":[],"source":["# st_sample_id_l = [SAMPLE_ID_N]\n"]},{"cell_type":"code","execution_count":19,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Adversarial training for ST slide 151509: \n","Start adversarial training...\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"908866e05e5245cc89b9b969b0b3463f","version_major":2,"version_minor":0},"text/plain":["Iterations:   0%|          | 0/3000 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["iter: 99 source loss: 1.236978 dis accu: 0.720562\n","iter: 199 source loss: 1.260481 dis accu: 0.827787\n","iter: 299 source loss: 1.201087 dis accu: 0.897172\n","iter: 399 source loss: 1.271319 dis accu: 0.726008\n","iter: 499 source loss: 1.299129 dis accu: 0.887329\n","iter: 599 source loss: 1.278309 dis accu: 0.910928\n","iter: 699 source loss: 1.286322 dis accu: 0.86607\n","iter: 799 source loss: 1.276529 dis accu: 0.902537\n","iter: 899 source loss: 1.235346 dis accu: 0.931219\n","iter: 999 source loss: 1.185005 dis accu: 0.907217\n","iter: 1099 source loss: 1.30424 dis accu: 0.782565\n","iter: 1199 source loss: 1.220146 dis accu: 0.909073\n","iter: 1299 source loss: 1.128674 dis accu: 0.90754\n","iter: 1399 source loss: 1.180274 dis accu: 0.684094\n","iter: 1499 source loss: 1.083691 dis accu: 0.515148\n","iter: 1599 source loss: 1.043124 dis accu: 0.671346\n","iter: 1699 source loss: 1.021036 dis accu: 0.589939\n","iter: 1799 source loss: 1.050688 dis accu: 0.398967\n","iter: 1899 source loss: 0.993762 dis accu: 0.871959\n","iter: 1999 source loss: 0.954818 dis accu: 0.737262\n","iter: 2099 source loss: 0.90858 dis accu: 0.818266\n","iter: 2199 source loss: 0.888662 dis accu: 0.63391\n","iter: 2299 source loss: 0.864746 dis accu: 0.586308\n","iter: 2399 source loss: 0.820398 dis accu: 0.425753\n","iter: 2499 source loss: 0.81383 dis accu: 0.692646\n","iter: 2599 source loss: 0.783601 dis accu: 0.75473\n","iter: 2699 source loss: 0.810852 dis accu: 0.11969\n","iter: 2799 source loss: 0.815008 dis accu: 0.39574\n","iter: 2899 source loss: 0.756811 dis accu: 0.967203\n","iter: 2999 source loss: 0.768443 dis accu: 0.954536\n","Adversarial training for ST slide 151510: \n","Start adversarial training...\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"443493335bd2493aadfef4c70daf19b4","version_major":2,"version_minor":0},"text/plain":["Iterations:   0%|          | 0/3000 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["iter: 99 source loss: 1.204959 dis accu: 0.925266\n","iter: 199 source loss: 1.219318 dis accu: 0.909881\n","iter: 299 source loss: 1.196306 dis accu: 0.992328\n","iter: 399 source loss: 1.265769 dis accu: 0.928635\n","iter: 499 source loss: 1.22779 dis accu: 0.94191\n","iter: 599 source loss: 1.267878 dis accu: 0.986563\n","iter: 699 source loss: 1.210657 dis accu: 0.720346\n","iter: 799 source loss: 1.199746 dis accu: 0.826459\n","iter: 899 source loss: 1.194351 dis accu: 0.589348\n","iter: 999 source loss: 1.066228 dis accu: 0.823171\n","iter: 1099 source loss: 1.028084 dis accu: 0.833279\n"]}],"source":["if TRAIN_USING_ALL_ST_SAMPLES:\n","    print(f\"Adversarial training for all ST slides\")\n","    save_folder = advtrain_folder\n","\n","    best_checkpoint = torch.load(os.path.join(pretrain_folder, f\"final_model.pth\"))\n","    model = best_checkpoint[\"model\"]\n","    model.to(device)\n","    model.advtraining()\n","\n","    train_adversarial(\n","        model,\n","        save_folder,\n","        sc_mix_train_s,\n","        lab_mix_train,\n","        mat_sp_train_s,\n","        dataloader_source_train,\n","        dataloader_target_train,\n","    )\n","\n","else:\n","    for sample_id in st_sample_id_l:\n","        print(f\"Adversarial training for ST slide {sample_id}: \")\n","\n","        save_folder = os.path.join(advtrain_folder, sample_id)\n","        if not os.path.isdir(save_folder):\n","            os.makedirs(save_folder)\n","\n","        best_checkpoint = torch.load(os.path.join(pretrain_folder, f\"final_model.pth\"))\n","        model = best_checkpoint[\"model\"]\n","        model.to(device)\n","        model.advtraining()\n","\n","        train_adversarial(\n","            model,\n","            save_folder,\n","            sc_mix_train_s,\n","            lab_mix_train,\n","            mat_sp_train_s_d[sample_id],\n","            dataloader_source_train,\n","            dataloader_target_train_d[sample_id],\n","        )\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# if TRAIN_USING_ALL_ST_SAMPLES:\n","#     best_checkpoint = torch.load(os.path.join(advtrain_folder, f\"final_model.pth\"))\n","# else:\n","#     best_checkpoint = torch.load(\n","#         os.path.join(advtrain_folder, SAMPLE_ID_N, f\"final_model.pth\")\n","#     )\n","\n","# model = best_checkpoint[\"model\"]\n","# model.to(device)\n","\n","# model.eval()\n","# model.set_encoder(\"source\")\n","\n","# pred_mix = (\n","#     torch.exp(model(torch.Tensor(sc_mix_test_s).to(device)))\n","#     .detach()\n","#     .cpu()\n","#     .numpy()\n","# )\n","\n","# cell_type_nums = sc_sub_dict.keys()\n","# nrows = ceil(len(cell_type_nums) / 5)\n","\n","# line_kws = {\"color\": \"tab:orange\"}\n","# scatter_kws = {\"s\": 5}\n","\n","# props = dict(facecolor=\"w\", alpha=0.5)\n","\n","# fig, ax = plt.subplots(\n","#     nrows,\n","#     5,\n","#     figsize=(25, 5 * nrows),\n","#     constrained_layout=True,\n","#     sharex=False,\n","#     sharey=True,\n","# )\n","# for i, visnum in enumerate(cell_type_nums):\n","#     sns.regplot(\n","#         x=pred_mix[:, visnum],\n","#         y=lab_mix_test[:, visnum],\n","#         line_kws=line_kws,\n","#         scatter_kws=scatter_kws,\n","#         ax=ax.flat[i],\n","#     ).set_title(sc_sub_dict[visnum])\n","\n","#     ax.flat[i].set_aspect(\"equal\")\n","#     ax.flat[i].set_xlabel(\"Predicted Proportion\")\n","\n","#     if i % 5 == 0:\n","#         ax.flat[i].set_ylabel(\"True Proportion\")\n","#     else:\n","#         ax.flat[i].set_ylabel(\"\")\n","#     ax.flat[i].set_xlim([0, 1])\n","#     ax.flat[i].set_ylim([0, 1])\n","\n","#     textstr = (\n","#         f\"MSE: {mean_squared_error(pred_mix[:,visnum], lab_mix_test[:,visnum]):.5f}\"\n","#     )\n","\n","#     # place a text box in upper left in axes coords\n","#     ax.flat[i].text(\n","#         0.95,\n","#         0.05,\n","#         textstr,\n","#         transform=ax.flat[i].transAxes,\n","#         verticalalignment=\"bottom\",\n","#         horizontalalignment=\"right\",\n","#         bbox=props,\n","#     )\n","\n","# for i in range(len(cell_type_nums), nrows * 5):\n","#     ax.flat[i].axis(\"off\")\n","\n","# plt.show()\n"]}],"metadata":{"kernelspec":{"display_name":"Python 3.10.4 ('agreda')","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.4 (main, Mar 31 2022, 08:41:55) [GCC 7.5.0]"},"orig_nbformat":4,"vscode":{"interpreter":{"hash":"330b2d1c36bdd59efd1cb99466680f0cb310a0929e0186587128f5e2b14c88ce"}}},"nbformat":4,"nbformat_minor":2}
