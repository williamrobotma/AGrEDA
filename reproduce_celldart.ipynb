{"cells":[{"cell_type":"markdown","metadata":{},"source":["  # Reproduce CellDART"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["import argparse\n","import os\n","import datetime\n","from itertools import chain\n","from copy import deepcopy\n","import warnings\n","\n","from tqdm.autonotebook import tqdm\n","\n","import yaml\n","import numpy as np\n","\n","import torch\n","from torch import nn\n","\n","from src.da_models.adda import ADDAST\n","from src.da_models.datasets import SpotDataset\n","from src.da_models.utils import set_requires_grad\n","from src.utils.dupstdout import DupStdout\n","from src.utils.data_loading import (\n","    load_spatial,\n","    load_sc,\n","    get_selected_dir,\n","    get_model_rel_path,\n",")\n","\n","script_start_time = datetime.datetime.now(datetime.timezone.utc)\n","\n","parser = argparse.ArgumentParser(description=\"Reproduce CellDART for ST\")\n","parser.add_argument(\n","    \"--config_fname\",\n","    \"-f\",\n","    type=str,\n","    help=\"Name of the config file to use\",\n",")\n","parser.add_argument(\n","    \"--njobs\",\n","    type=int,\n","    default=0,\n","    help=\"Number of jobs to use for parallel processing.\",\n",")\n","parser.add_argument(\n","    \"--cuda\",\n","    \"-c\",\n","    default=None,\n","    help=\"gpu index to use\",\n",")\n",""]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# args = parser.parse_args()\n","# CONFIG_FNAME = args.config_fname\n","# CUDA_INDEX = args.cuda\n","# NUM_WORKERS = args.njobs\n","\n","CONFIG_FNAME = \"celldart1_bnfix.yml\"\n","CUDA_INDEX = None\n","NUM_WORKERS = 0"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# torch_params = {}\n","\n","# torch_params[\"manual_seed\"] = 1205\n","# torch_params[\"cuda_i\"] = 0\n","\n",""]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# data_params = {}\n","# # Data path and parameters\n","# data_params[\"data_dir\"] = \"data\"\n","# data_params[\"train_using_all_st_samples\"] = False\n","# data_params[\"n_markers\"] = 20\n","# data_params[\"all_genes\"] = False\n","\n","# # Pseudo-spot parameters\n","# data_params[\"n_spots\"] = 20000\n","# data_params[\"n_mix\"] = 8\n","\n","# # ST spot parameters\n","# data_params[\"st_split\"] = False\n","# data_params[\"sample_id_n\"] = \"151673\"\n","\n","# # Scaler parameter\n","# data_params[\"scaler_name\"] = \"celldart\"\n","\n",""]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# model_params = {}\n","\n","# # Model parameters\n","MODEL_NAME = \"CellDART\"\n","# model_params[\"model_version\"] = \"celldart1_bnfix\"\n","\n","# model_params[\"celldart_kwargs\"] = {\n","#     \"emb_dim\": 64,\n","#     \"bn_momentum\": 0.01,\n","# }\n","\n",""]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# train_params = {}\n","\n","# train_params[\"batch_size\"] = 512\n","# train_params[\"num_workers\"] = 16\n","# # Pretraining parameters\n","# # SAMPLE_ID_N = \"151673\"\n","\n","# train_params[\"initial_train_epochs\"] = 10\n","\n","# train_params[\"early_stop_crit\"] = 100\n","# train_params[\"min_epochs\"] = train_params[\"initial_train_epochs\"]\n","\n","# # Adversarial training parameters\n","# train_params[\"early_stop_crit_adv\"] = 10\n","# train_params[\"min_epochs_adv\"] = 10\n","\n","# train_params[\"n_iter\"] = 3000\n","# train_params[\"alpha_lr\"] = 5\n","# train_params[\"alpha\"] = 0.6\n","\n",""]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# config = {\n","#     \"torch_params\": torch_params,\n","#     \"data_params\": data_params,\n","#     \"model_params\": model_params,\n","#     \"train_params\": train_params,\n","# }\n","\n","with open(os.path.join(\"configs\", MODEL_NAME, CONFIG_FNAME), \"r\") as f:\n","    config = yaml.safe_load(f)\n","\n","torch_params = config[\"torch_params\"]\n","data_params = config[\"data_params\"]\n","model_params = config[\"model_params\"]\n","train_params = config[\"train_params\"]\n","\n","if not \"pretraining\" in train_params:\n","    train_params[\"pretraining\"] = True\n","    with open(os.path.join(\"configs\", MODEL_NAME, CONFIG_FNAME), \"w\") as f:\n","        yaml.safe_dump(config, f)\n","\n","print(yaml.safe_dump(config))\n","\n",""]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["if CUDA_INDEX is not None:\n","    device = torch.device(f\"cuda:{CUDA_INDEX}\" if torch.cuda.is_available() else \"cpu\")\n","else:\n","    device = torch.device(f\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","if device == \"cpu\":\n","    warnings.warn(\"Using CPU\", stacklevel=2)\n",""]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["if \"manual_seed\" in torch_params:\n","    torch_seed = torch_params[\"manual_seed\"]\n","    torch_seed_path = str(torch_params[\"manual_seed\"])\n","else:\n","    torch_seed = int(script_start_time.timestamp())\n","    # torch_seed_path = script_start_time.strftime(\"%Y-%m-%d_%Hh%Mm%Ss\")\n","    torch_seed_path = \"random\"\n","\n","torch.manual_seed(torch_seed)\n","np.random.seed(torch_seed)\n","\n",""]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["model_folder = get_model_rel_path(\n","    MODEL_NAME,\n","    model_params[\"model_version\"],\n","    scaler_name=data_params[\"scaler_name\"],\n","    n_markers=data_params[\"n_markers\"],\n","    all_genes=data_params[\"all_genes\"],\n","    n_mix=data_params[\"n_mix\"],\n","    n_spots=data_params[\"n_spots\"],\n","    st_split=data_params[\"st_split\"],\n","    torch_seed_path=torch_seed_path,\n",")\n","model_folder = os.path.join(\"model\", model_folder)\n","\n","if not os.path.isdir(model_folder):\n","    os.makedirs(model_folder)\n","    print(model_folder)\n","\n",""]},{"cell_type":"markdown","metadata":{},"source":["  # Data load\n",""]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["selected_dir = get_selected_dir(\n","    data_params[\"data_dir\"], data_params[\"n_markers\"], data_params[\"all_genes\"]\n",")\n","\n","# Load spatial data\n","mat_sp_d, mat_sp_train, st_sample_id_l = load_spatial(\n","    selected_dir,\n","    data_params[\"scaler_name\"],\n","    train_using_all_st_samples=data_params[\"train_using_all_st_samples\"],\n","    st_split=data_params[\"st_split\"],\n",")\n","\n","# Load sc data\n","sc_mix_d, lab_mix_d, sc_sub_dict, sc_sub_dict2 = load_sc(\n","    selected_dir,\n","    data_params[\"scaler_name\"],\n","    n_mix=data_params[\"n_mix\"],\n","    n_spots=data_params[\"n_spots\"],\n",")\n","\n",""]},{"cell_type":"markdown","metadata":{},"source":["  # Training: Adversarial domain adaptation for cell fraction estimation"]},{"cell_type":"markdown","metadata":{},"source":["  ## Prepare dataloaders"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["### source dataloaders\n","source_train_set = SpotDataset(\n","    deepcopy(sc_mix_d[\"train\"]), deepcopy(lab_mix_d[\"train\"])\n",")\n","source_val_set = SpotDataset(deepcopy(sc_mix_d[\"val\"]), deepcopy(lab_mix_d[\"val\"]))\n","source_test_set = SpotDataset(deepcopy(sc_mix_d[\"test\"]), deepcopy(lab_mix_d[\"test\"]))\n","\n","dataloader_source_train = torch.utils.data.DataLoader(\n","    source_train_set,\n","    batch_size=train_params[\"batch_size\"],\n","    shuffle=True,\n","    num_workers=NUM_WORKERS,\n","    pin_memory=True,\n",")\n","dataloader_source_val = torch.utils.data.DataLoader(\n","    source_val_set,\n","    batch_size=train_params[\"batch_size\"],\n","    shuffle=False,\n","    num_workers=NUM_WORKERS,\n","    pin_memory=False,\n",")\n","dataloader_source_test = torch.utils.data.DataLoader(\n","    source_test_set,\n","    batch_size=train_params[\"batch_size\"],\n","    shuffle=False,\n","    num_workers=NUM_WORKERS,\n","    pin_memory=False,\n",")\n","\n","# ### target dataloaders\n","# target_test_set_d = {}\n","# for sample_id in st_sample_id_l:\n","#     target_test_set_d[sample_id] = SpotDataset(deepcopy(mat_sp_d[\"test\"][sample_id]))\n","\n","# dataloader_target_test_d = {}\n","# for sample_id in st_sample_id_l:\n","#     dataloader_target_test_d[sample_id] = torch.utils.data.DataLoader(\n","#         target_test_set_d[sample_id],\n","#         batch_size=BATCH_SIZE,\n","#         shuffle=False,\n","#         num_workers=NUM_WORKERS,\n","#         pin_memory=False,\n","#     )\n","\n","# if TRAIN_USING_ALL_ST_SAMPLES:\n","#     target_train_set = SpotDataset(deepcopy(mat_sp_train_s))\n","#     dataloader_target_train = torch.utils.data.DataLoader(\n","#         target_train_set,\n","#         batch_size=BATCH_SIZE,\n","#         shuffle=True,\n","#         num_workers=NUM_WORKERS,\n","#         pin_memory=True,\n","#     )\n","# else:\n","#     target_train_set_d = {}\n","#     dataloader_target_train_d = {}\n","#     for sample_id in st_sample_id_l:\n","#         target_train_set_d[sample_id] = SpotDataset(\n","#             deepcopy(mat_sp_d[\"train\"][sample_id])\n","#         )\n","#         dataloader_target_train_d[sample_id] = torch.utils.data.DataLoader(\n","#             target_train_set_d[sample_id],\n","#             batch_size=BATCH_SIZE,\n","#             shuffle=True,\n","#             num_workers=NUM_WORKERS,\n","#             pin_memory=True,\n","#         )\n","\n","# if TRAIN_USING_ALL_ST_SAMPLES:\n","#     target_train_set = SpotDataset(deepcopy(mat_sp_train))\n","#     dataloader_target_train = torch.utils.data.DataLoader(\n","#         target_train_set,\n","#         batch_size=BATCH_SIZE,\n","#         shuffle=True,\n","#         num_workers=NUM_WORKERS,\n","#         pin_memory=True,\n","#     )\n","\n","### target dataloaders\n","target_train_set_d = {}\n","dataloader_target_train_d = {}\n","if data_params[\"st_split\"]:\n","    target_val_set_d = {}\n","    target_test_set_d = {}\n","\n","    dataloader_target_val_d = {}\n","    dataloader_target_test_d = {}\n","    for sample_id in st_sample_id_l:\n","        target_train_set_d[sample_id] = SpotDataset(\n","            deepcopy(mat_sp_d[sample_id][\"train\"])\n","        )\n","        target_val_set_d[sample_id] = SpotDataset(deepcopy(mat_sp_d[sample_id][\"val\"]))\n","        target_test_set_d[sample_id] = SpotDataset(\n","            deepcopy(mat_sp_d[sample_id][\"test\"])\n","        )\n","\n","        dataloader_target_train_d[sample_id] = torch.utils.data.DataLoader(\n","            target_train_set_d[sample_id],\n","            batch_size=train_params[\"batch_size\"],\n","            shuffle=True,\n","            num_workers=NUM_WORKERS,\n","            pin_memory=False,\n","        )\n","        dataloader_target_val_d[sample_id] = torch.utils.data.DataLoader(\n","            target_val_set_d[sample_id],\n","            batch_size=train_params[\"batch_size\"],\n","            shuffle=False,\n","            num_workers=NUM_WORKERS,\n","            pin_memory=False,\n","        )\n","        dataloader_target_test_d[sample_id] = torch.utils.data.DataLoader(\n","            target_test_set_d[sample_id],\n","            batch_size=train_params[\"batch_size\"],\n","            shuffle=False,\n","            num_workers=NUM_WORKERS,\n","            pin_memory=False,\n","        )\n","\n","else:\n","    target_test_set_d = {}\n","    dataloader_target_test_d = {}\n","    for sample_id in st_sample_id_l:\n","        target_train_set_d[sample_id] = SpotDataset(\n","            deepcopy(mat_sp_d[sample_id][\"train\"])\n","        )\n","        dataloader_target_train_d[sample_id] = torch.utils.data.DataLoader(\n","            target_train_set_d[sample_id],\n","            batch_size=train_params[\"batch_size\"],\n","            shuffle=True,\n","            num_workers=NUM_WORKERS,\n","            pin_memory=False,\n","        )\n","\n","        target_test_set_d[sample_id] = SpotDataset(\n","            deepcopy(mat_sp_d[sample_id][\"test\"])\n","        )\n","        dataloader_target_test_d[sample_id] = torch.utils.data.DataLoader(\n","            target_test_set_d[sample_id],\n","            batch_size=train_params[\"batch_size\"],\n","            shuffle=False,\n","            num_workers=NUM_WORKERS,\n","            pin_memory=False,\n","        )\n","\n","\n","if data_params[\"train_using_all_st_samples\"]:\n","    target_train_set = SpotDataset(mat_sp_train)\n","    dataloader_target_train = torch.utils.data.DataLoader(\n","        target_train_set,\n","        batch_size=train_params[\"batch_size\"],\n","        shuffle=True,\n","        num_workers=NUM_WORKERS,\n","        pin_memory=True,\n","    )\n","\n",""]},{"cell_type":"markdown","metadata":{},"source":["  ## Define Model"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["model = ADDAST(\n","    inp_dim=sc_mix_d[\"train\"].shape[1],\n","    ncls_source=lab_mix_d[\"train\"].shape[1],\n","    **model_params[\"celldart_kwargs\"],\n",")\n","\n","## CellDART uses just one encoder!\n","model.target_encoder = model.source_encoder\n","print(model.to(device))\n","\n",""]},{"cell_type":"markdown","metadata":{},"source":["  ## Pretrain"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["pretrain_folder = os.path.join(model_folder, \"pretrain\")\n","\n","if not os.path.isdir(pretrain_folder):\n","    os.makedirs(pretrain_folder)\n","\n",""]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["pre_optimizer = torch.optim.Adam(\n","    model.parameters(), lr=0.001, betas=(0.9, 0.999), eps=1e-07\n",")\n","\n","criterion_clf = nn.KLDivLoss(reduction=\"batchmean\")\n","\n",""]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["def model_loss(x, y_true, model):\n","    x = x.to(torch.float32).to(device)\n","    y_true = y_true.to(torch.float32).to(device)\n","\n","    y_pred = model(x)\n","\n","    loss = criterion_clf(y_pred, y_true)\n","\n","    return loss\n","\n","\n","def run_pretrain_epoch(model, dataloader, optimizer=None, inner=None):\n","    loss_running = []\n","    mean_weights = []\n","\n","    is_training = model.training and optimizer\n","\n","    for _, batch in enumerate(dataloader):\n","        loss = model_loss(*batch, model)\n","        loss_running.append(loss.item())\n","        mean_weights.append(len(batch))  # we will weight average by batch size later\n","\n","        if is_training:\n","            optimizer.zero_grad()\n","            loss.backward()\n","            optimizer.step()\n","        if inner:\n","            inner.update(1)\n","    return loss_running, mean_weights\n","\n","\n","def compute_acc(dataloader, model):\n","\n","    model.eval()\n","    with torch.no_grad():\n","        loss_running, mean_weights = run_pretrain_epoch(model, dataloader)\n","\n","    return np.average(loss_running, weights=mean_weights)\n","\n",""]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["model.pretraining()\n","\n",""]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Initialize lists to store loss and accuracy values\n","loss_history = []\n","loss_history_val = []\n","\n","loss_history_running = []\n","\n","# Early Stopping\n","best_loss_val = np.inf\n","early_stop_count = 0\n","\n","\n","with DupStdout().dup_to_file(os.path.join(pretrain_folder, \"log.txt\"), \"w\") as f_log:\n","    # Train\n","    print(\"Start pretrain...\")\n","    outer = tqdm(total=train_params[\"initial_train_epochs\"], desc=\"Epochs\", position=0)\n","    inner = tqdm(total=len(dataloader_source_train), desc=f\"Batch\", position=1)\n","\n","    print(\" Epoch | Train Loss | Val Loss   \")\n","    print(\"---------------------------------\")\n","    checkpoint = {\n","        \"epoch\": -1,\n","        \"model\": model,\n","        \"optimizer\": pre_optimizer,\n","    }\n","    for epoch in range(train_params[\"initial_train_epochs\"]):\n","        inner.refresh()  # force print final state\n","        inner.reset()  # reuse bar\n","\n","        checkpoint[\"epoch\"] = epoch\n","\n","        # Train mode\n","        model.train()\n","\n","        loss_running, mean_weights = run_pretrain_epoch(\n","            model, dataloader_source_train, optimizer=pre_optimizer, inner=inner\n","        )\n","\n","        loss_history.append(np.average(loss_running, weights=mean_weights))\n","        loss_history_running.append(loss_running)\n","\n","        # Evaluate mode\n","        model.eval()\n","        with torch.no_grad():\n","            curr_loss_val = compute_acc(dataloader_source_val, model)\n","            loss_history_val.append(curr_loss_val)\n","\n","        # Print the results\n","        outer.update(1)\n","        out_string = (\n","            f\" {epoch:5d} \" f\"| {loss_history[-1]:<10.8f} \" f\"| {curr_loss_val:<10.8f} \"\n","        )\n","\n","        # Save the best weights\n","        if curr_loss_val < best_loss_val:\n","            best_loss_val = curr_loss_val\n","            torch.save(checkpoint, os.path.join(pretrain_folder, f\"best_model.pth\"))\n","            early_stop_count = 0\n","\n","            out_string += \"<-- new best val loss\"\n","\n","        tqdm.write(out_string)\n","\n","        # Save checkpoint every 10\n","        if epoch % 10 == 0 or epoch >= train_params[\"initial_train_epochs\"] - 1:\n","            torch.save(checkpoint, os.path.join(pretrain_folder, f\"checkpt{epoch}.pth\"))\n","\n","        # check to see if validation loss has plateau'd\n","        if (\n","            early_stop_count >= train_params[\"early_stop_crit\"]\n","            and epoch >= train_params[\"min_epochs\"] - 1\n","        ):\n","            print(\n","                f\"Validation loss plateaued after {early_stop_count} at epoch {epoch}\"\n","            )\n","            torch.save(\n","                checkpoint, os.path.join(pretrain_folder, f\"earlystop{epoch}.pth\")\n","            )\n","            break\n","\n","        early_stop_count += 1\n","\n","    model.eval()\n","    with torch.no_grad():\n","        curr_loss_train = compute_acc(dataloader_source_train, model)\n","\n","    print(f\"Final train loss: {curr_loss_train}\")\n","    # Save final model\n","    torch.save(checkpoint, os.path.join(pretrain_folder, f\"final_model.pth\"))\n","\n",""]},{"cell_type":"markdown","metadata":{},"source":["  ## Adversarial Adaptation"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["advtrain_folder = os.path.join(model_folder, \"advtrain\")\n","\n","if not os.path.isdir(advtrain_folder):\n","    os.makedirs(advtrain_folder)\n","\n",""]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["def batch_generator(data, batch_size):\n","    \"\"\"Generate batches of data.\n","\n","    Given a list of numpy data, it iterates over the list and returns batches of\n","    the same size.\n","    \"\"\"\n","    all_examples_indices = len(data[0])\n","    while True:\n","        mini_batch_indices = np.random.choice(\n","            all_examples_indices, size=batch_size, replace=False\n","        )\n","        tbr = [k[mini_batch_indices] for k in data]\n","        yield tbr\n","\n",""]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["criterion_dis = nn.CrossEntropyLoss()\n","criterion_clf_nored = nn.KLDivLoss(reduction=\"none\")\n","\n","\n","def discrim_loss_accu(x, y_dis, model):\n","    x = x.to(torch.float32).to(device)\n","\n","    emb = model.source_encoder(x)\n","    y_pred = model.dis(emb)\n","\n","    loss = criterion_dis(y_pred, y_dis)\n","\n","    accu = torch.mean(\n","        (torch.flatten(torch.argmax(y_pred, dim=1)) == y_dis).to(torch.float32)\n","    ).cpu()\n","\n","    return loss, accu\n","\n","\n","def compute_acc_dis(dataloader_source, dataloader_target, model):\n","    len_target = len(dataloader_target)\n","    len_source = len(dataloader_source)\n","\n","    loss_running = []\n","    accu_running = []\n","    mean_weights = []\n","    model.eval()\n","    model.source_encoder.eval()\n","    model.dis.eval()\n","    with torch.no_grad():\n","        for y_val, dl in zip([1, 0], [dataloader_target, dataloader_source]):\n","            for _, (x, _) in enumerate(dl):\n","\n","                y_dis = torch.full(\n","                    (x.shape[0],), y_val, device=device, dtype=torch.long\n","                )\n","\n","                loss, accu = discrim_loss_accu(x, y_dis, model)\n","\n","                accu_running.append(accu)\n","                loss_running.append(loss.item())\n","\n","                # we will weight average by batch size later\n","                mean_weights.append(len(x))\n","\n","    return (\n","        np.average(loss_running, weights=mean_weights),\n","        np.average(accu_running, weights=mean_weights),\n","    )\n","\n",""]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["def train_adversarial(\n","    model,\n","    save_folder,\n","    sc_mix_train_s,\n","    lab_mix_train_s,\n","    mat_sp_train_s,\n","    dataloader_source_train_eval,\n","    dataloader_target_train_eval,\n","):\n","\n","    model.to(device)\n","    model.advtraining()\n","    model.set_encoder(\"source\")\n","\n","    S_batches = batch_generator(\n","        [sc_mix_train_s.copy(), lab_mix_train_s.copy()], train_params[\"batch_size\"]\n","    )\n","    T_batches = batch_generator(\n","        [mat_sp_train_s.copy(), np.ones(shape=(len(mat_sp_train_s), 2))],\n","        train_params[\"batch_size\"],\n","    )\n","\n","    enc_optimizer = torch.optim.Adam(\n","        chain(\n","            model.source_encoder.parameters(),\n","            model.dis.parameters(),\n","            model.clf.parameters(),\n","        ),\n","        lr=0.001,\n","        betas=(0.9, 0.999),\n","        eps=1e-07,\n","    )\n","\n","    dis_optimizer = torch.optim.Adam(\n","        chain(model.source_encoder.parameters(), model.dis.parameters()),\n","        lr=train_params[\"alpha_lr\"] * 0.001,\n","        betas=(0.9, 0.999),\n","        eps=1e-07,\n","    )\n","\n","    # Initialize lists to store loss and accuracy values\n","    loss_history_running = []\n","    with DupStdout().dup_to_file(os.path.join(save_folder, \"log.txt\"), \"w\") as f_log:\n","        # Train\n","        print(\"Start adversarial training...\")\n","        outer = tqdm(total=train_params[\"n_iter\"], desc=\"Iterations\", position=0)\n","\n","        checkpoint = {\n","            \"epoch\": -1,\n","            \"model\": model,\n","            \"dis_optimizer\": dis_optimizer,\n","            \"enc_optimizer\": enc_optimizer,\n","        }\n","        for iters in range(train_params[\"n_iter\"]):\n","            checkpoint[\"epoch\"] = iters\n","\n","            model.train()\n","            model.dis.train()\n","            model.clf.train()\n","            model.source_encoder.train()\n","\n","            x_source, y_true = next(S_batches)\n","            x_target, _ = next(T_batches)\n","\n","            ## Train encoder\n","            set_requires_grad(model.source_encoder, True)\n","            set_requires_grad(model.clf, True)\n","            set_requires_grad(model.dis, True)\n","\n","            # save discriminator weights\n","            dis_weights = deepcopy(model.dis.state_dict())\n","            new_dis_weights = {}\n","            for k in dis_weights:\n","                # if \"num_batches_tracked\" not in k:\n","                new_dis_weights[k] = dis_weights[k]\n","\n","            dis_weights = new_dis_weights\n","\n","            x_source, x_target, y_true, = (\n","                torch.Tensor(x_source),\n","                torch.Tensor(x_target),\n","                torch.Tensor(y_true),\n","            )\n","            x_source, x_target, y_true, = (\n","                x_source.to(device),\n","                x_target.to(device),\n","                y_true.to(device),\n","            )\n","\n","            x = torch.cat((x_source, x_target))\n","\n","            # save for discriminator later\n","            x_d = x.detach()\n","\n","            # y_dis is the REAL one\n","            y_dis = torch.cat(\n","                [\n","                    torch.zeros(x_source.shape[0], device=device, dtype=torch.long),\n","                    torch.ones(x_target.shape[0], device=device, dtype=torch.long),\n","                ]\n","            )\n","            y_dis_flipped = 1 - y_dis.detach()\n","\n","            emb = model.source_encoder(x).view(x.shape[0], -1)\n","\n","            y_dis_pred = model.dis(emb)\n","            y_clf_pred = model.clf(emb)\n","\n","            # we use flipped because we want to confuse discriminator\n","            loss_dis = criterion_dis(y_dis_pred, y_dis_flipped)\n","\n","            # Set true = predicted for target samples since we don't know what it is\n","            y_clf_true = torch.cat(\n","                (y_true, torch.zeros_like(y_clf_pred[y_true.shape[0] :]))\n","            )\n","\n","            # Loss fn does mean over all samples including target\n","            loss_clf = criterion_clf_nored(y_clf_pred, y_clf_true)\n","            clf_sample_weights = torch.cat(\n","                (torch.ones((x_source.shape[0],)), torch.zeros((x_target.shape[0],)))\n","            ).to(device)\n","            # batchmean with sample weights\n","            loss_clf = (loss_clf.sum(dim=1) * clf_sample_weights).mean()\n","\n","            # Scale back up loss so mean doesn't include target\n","            # loss = (x.shape[0] / x_source.shape[0]) * loss_clf + ALPHA * loss_dis\n","            loss = loss_clf + train_params[\"alpha\"] * loss_dis\n","\n","            # loss = loss_clf + ALPHA * loss_dis\n","\n","            enc_optimizer.zero_grad()\n","            loss.backward()\n","            enc_optimizer.step()\n","\n","            model.dis.load_state_dict(dis_weights, strict=False)\n","\n","            ## Train discriminator\n","            set_requires_grad(model.source_encoder, True)\n","            set_requires_grad(model.clf, True)\n","            set_requires_grad(model.dis, True)\n","\n","            # save encoder and clf weights\n","            source_encoder_weights = deepcopy(model.source_encoder.state_dict())\n","            clf_weights = deepcopy(model.clf.state_dict())\n","\n","            new_clf_weights = {}\n","            for k in clf_weights:\n","                # if \"num_batches_tracked\" not in k:\n","                new_clf_weights[k] = clf_weights[k]\n","\n","            clf_weights = new_clf_weights\n","\n","            new_source_encoder_weights = {}\n","            for k in source_encoder_weights:\n","                # if \"num_batches_tracked\" not in k:\n","                new_source_encoder_weights[k] = source_encoder_weights[k]\n","\n","            source_encoder_weights = new_source_encoder_weights\n","\n","            emb = model.source_encoder(x_d).view(x_d.shape[0], -1)\n","            y_pred = model.dis(emb)\n","\n","            # we use the real domain labels to train discriminator\n","            loss = criterion_dis(y_pred, y_dis)\n","\n","            dis_optimizer.zero_grad()\n","            loss.backward()\n","            dis_optimizer.step()\n","\n","            model.clf.load_state_dict(clf_weights, strict=False)\n","            model.source_encoder.load_state_dict(source_encoder_weights, strict=False)\n","\n","            # Save checkpoint every 100\n","            if iters % 100 == 99 or iters >= train_params[\"n_iter\"] - 1:\n","                torch.save(checkpoint, os.path.join(save_folder, f\"checkpt{iters}.pth\"))\n","\n","                model.eval()\n","                source_loss = compute_acc(dataloader_source_train_eval, model)\n","                _, dis_accu = compute_acc_dis(\n","                    dataloader_source_train_eval, dataloader_target_train_eval, model\n","                )\n","\n","                # Print the results\n","                tqdm.write(\n","                    f\"iter: {iters} source loss: {source_loss} dis accu: {dis_accu}\"\n","                )\n","\n","            outer.update(1)\n","\n","    torch.save(checkpoint, os.path.join(save_folder, f\"final_model.pth\"))\n","\n",""]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# st_sample_id_l = [SAMPLE_ID_N]\n","\n",""]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["if data_params[\"train_using_all_st_samples\"]:\n","    print(f\"Adversarial training for all ST slides\")\n","    save_folder = advtrain_folder\n","\n","    best_checkpoint = torch.load(os.path.join(pretrain_folder, f\"final_model.pth\"))\n","    model = best_checkpoint[\"model\"]\n","    model.to(device)\n","    model.advtraining()\n","\n","    train_adversarial(\n","        model,\n","        save_folder,\n","        sc_mix_d[\"train\"],\n","        lab_mix_d[\"train\"],\n","        mat_sp_train,\n","        dataloader_source_train,\n","        dataloader_target_train,\n","    )\n","\n","else:\n","    for sample_id in st_sample_id_l:\n","        print(f\"Adversarial training for ST slide {sample_id}: \")\n","\n","        save_folder = os.path.join(advtrain_folder, sample_id)\n","        if not os.path.isdir(save_folder):\n","            os.makedirs(save_folder)\n","\n","        best_checkpoint = torch.load(os.path.join(pretrain_folder, f\"final_model.pth\"))\n","        model = best_checkpoint[\"model\"]\n","        model.to(device)\n","        model.advtraining()\n","\n","        train_adversarial(\n","            model,\n","            save_folder,\n","            sc_mix_d[\"train\"],\n","            lab_mix_d[\"train\"],\n","            mat_sp_d[sample_id][\"train\"],\n","            dataloader_source_train,\n","            dataloader_target_train_d[sample_id],\n","        )\n",""]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["with open(os.path.join(model_folder, \"config.yml\"), \"w\") as f:\n","    yaml.safe_dump(config, f)\n",""]}],"nbformat":4,"nbformat_minor":2,"metadata":{"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":3},"orig_nbformat":4}}