{"cells":[{"cell_type":"markdown","metadata":{},"source":[" # ADDA for ST"]},{"cell_type":"code","execution_count":1,"metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["/tmp/ipykernel_1164356/2753113568.py:7: TqdmExperimentalWarning: Using `tqdm.autonotebook.tqdm` in notebook mode. Use `tqdm.tqdm` instead to force console mode (e.g. in jupyter console)\n","  from tqdm.autonotebook import tqdm\n"]}],"source":["import os\n","import datetime\n","from itertools import chain\n","from copy import deepcopy\n","import warnings\n","\n","from tqdm.autonotebook import tqdm\n","\n","import h5py\n","import pickle\n","import numpy as np\n","\n","import torch\n","from torch import nn\n","\n","from src.da_models.adda import ADDAST\n","from src.da_models.datasets import SpotDataset\n","from src.da_models.utils import set_requires_grad\n","from src.utils.data_loading import load_spatial, load_sc\n","\n","# datetime object containing current date and time\n","script_start_time = datetime.datetime.now().strftime(\"%Y-%m-%d_%Hh%Mm%S\")\n"]},{"cell_type":"code","execution_count":2,"metadata":{},"outputs":[],"source":["device = torch.device(\"cuda:3\" if torch.cuda.is_available() else \"cpu\")\n","if device == \"cpu\":\n","    warnings.warn(\"Using CPU\", stacklevel=2)\n"]},{"cell_type":"code","execution_count":3,"metadata":{},"outputs":[],"source":["NUM_MARKERS = 20\n","N_MIX = 8\n","N_SPOTS = 20000\n","TRAIN_USING_ALL_ST_SAMPLES = False\n","\n","ST_SPLIT = False\n","\n","SAMPLE_ID_N = \"151673\"\n","\n","BATCH_SIZE = 512\n","NUM_WORKERS = 4\n","INITIAL_TRAIN_EPOCHS = 10\n","\n","EARLY_STOP_CRIT = 100\n","MIN_EPOCHS = INITIAL_TRAIN_EPOCHS\n","\n","\n","EARLY_STOP_CRIT_ADV = 10\n","MIN_EPOCHS_ADV = 10\n","\n","SPATIALLIBD_DIR = \"./data/spatialLIBD\"\n","SC_DLPFC_PATH = \"./data/sc_dlpfc/adata_sc_dlpfc.h5ad\"\n","\n","PROCESSED_DATA_DIR = \"./data/preprocessed_markers_celldart\"\n","\n","MODEL_NAME = \"CellDART\"\n","\n","\n","celldart_kwargs = {\n","    \"emb_dim\": 64,\n","    \"bn_momentum\": 0.01,\n","}\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["N_ITER = 3000\n","ALPHA_LR = 5\n","ALPHA = 0.6\n"]},{"cell_type":"code","execution_count":4,"metadata":{},"outputs":[],"source":["model_folder = os.path.join(\"model\", MODEL_NAME, script_start_time)\n","\n","model_folder = os.path.join(\"model\", MODEL_NAME, \"bn_fix\")\n","\n","if not os.path.isdir(model_folder):\n","    os.makedirs(model_folder)\n","    print(model_folder)\n"]},{"cell_type":"markdown","metadata":{},"source":[" # Data load\n"]},{"cell_type":"code","execution_count":5,"metadata":{},"outputs":[],"source":["# Load spatial data\n","mat_sp_d, mat_sp_train_s, st_sample_id_l = load_spatial(\n","    TRAIN_USING_ALL_ST_SAMPLES, PROCESSED_DATA_DIR, ST_SPLIT\n",")\n","\n","# Load sc data\n","sc_mix_d, lab_mix_d, sc_sub_dict, sc_sub_dict2 = load_sc(PROCESSED_DATA_DIR)\n"]},{"cell_type":"markdown","metadata":{},"source":[" # Training: Adversarial domain adaptation for cell fraction estimation"]},{"cell_type":"markdown","metadata":{},"source":[" ## Prepare dataloaders"]},{"cell_type":"code","execution_count":6,"metadata":{},"outputs":[],"source":["### source dataloaders\n","source_train_set = SpotDataset(\n","    deepcopy(sc_mix_d[\"train\"]), deepcopy(lab_mix_d[\"train\"])\n",")\n","source_val_set = SpotDataset(deepcopy(sc_mix_d[\"val\"]), deepcopy(lab_mix_d[\"val\"]))\n","source_test_set = SpotDataset(deepcopy(sc_mix_d[\"test\"]), deepcopy(lab_mix_d[\"test\"]))\n","\n","dataloader_source_train = torch.utils.data.DataLoader(\n","    source_train_set,\n","    batch_size=BATCH_SIZE,\n","    shuffle=True,\n","    num_workers=NUM_WORKERS,\n","    pin_memory=True,\n",")\n","dataloader_source_val = torch.utils.data.DataLoader(\n","    source_val_set,\n","    batch_size=BATCH_SIZE,\n","    shuffle=False,\n","    num_workers=NUM_WORKERS,\n","    pin_memory=False,\n",")\n","dataloader_source_test = torch.utils.data.DataLoader(\n","    source_test_set,\n","    batch_size=BATCH_SIZE,\n","    shuffle=False,\n","    num_workers=NUM_WORKERS,\n","    pin_memory=False,\n",")\n","\n","### target dataloaders\n","target_test_set_d = {}\n","for sample_id in st_sample_id_l:\n","    target_test_set_d[sample_id] = SpotDataset(deepcopy(mat_sp_d[\"test\"][sample_id]))\n","\n","dataloader_target_test_d = {}\n","for sample_id in st_sample_id_l:\n","    dataloader_target_test_d[sample_id] = torch.utils.data.DataLoader(\n","        target_test_set_d[sample_id],\n","        batch_size=BATCH_SIZE,\n","        shuffle=False,\n","        num_workers=NUM_WORKERS,\n","        pin_memory=False,\n","    )\n","\n","if TRAIN_USING_ALL_ST_SAMPLES:\n","    target_train_set = SpotDataset(deepcopy(mat_sp_train_s))\n","    dataloader_target_train = torch.utils.data.DataLoader(\n","        target_train_set,\n","        batch_size=BATCH_SIZE,\n","        shuffle=True,\n","        num_workers=NUM_WORKERS,\n","        pin_memory=True,\n","    )\n","else:\n","    target_train_set_d = {}\n","    dataloader_target_train_d = {}\n","    for sample_id in st_sample_id_l:\n","        target_train_set_d[sample_id] = SpotDataset(\n","            deepcopy(mat_sp_d[\"train\"][sample_id])\n","        )\n","        dataloader_target_train_d[sample_id] = torch.utils.data.DataLoader(\n","            target_train_set_d[sample_id],\n","            batch_size=BATCH_SIZE,\n","            shuffle=True,\n","            num_workers=NUM_WORKERS,\n","            pin_memory=True,\n","        )\n"]},{"cell_type":"markdown","metadata":{},"source":[" ## Define Model"]},{"cell_type":"code","execution_count":7,"metadata":{},"outputs":[{"data":{"text/plain":["ADDAST(\n","  (source_encoder): MLPEncoder(\n","    (encoder): Sequential(\n","      (0): Linear(in_features=367, out_features=1024, bias=True)\n","      (1): BatchNorm1d(1024, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n","      (2): ELU(alpha=1.0)\n","      (3): Linear(in_features=1024, out_features=64, bias=True)\n","      (4): BatchNorm1d(64, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n","      (5): ELU(alpha=1.0)\n","    )\n","  )\n","  (target_encoder): MLPEncoder(\n","    (encoder): Sequential(\n","      (0): Linear(in_features=367, out_features=1024, bias=True)\n","      (1): BatchNorm1d(1024, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n","      (2): ELU(alpha=1.0)\n","      (3): Linear(in_features=1024, out_features=64, bias=True)\n","      (4): BatchNorm1d(64, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n","      (5): ELU(alpha=1.0)\n","    )\n","  )\n","  (dis): Discriminator(\n","    (head): Sequential(\n","      (0): Linear(in_features=64, out_features=32, bias=True)\n","      (1): BatchNorm1d(32, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n","      (2): ELU(alpha=1.0)\n","      (3): Dropout(p=0.5, inplace=False)\n","      (4): Linear(in_features=32, out_features=2, bias=True)\n","    )\n","  )\n","  (clf): Predictor(\n","    (head): Sequential(\n","      (0): Linear(in_features=64, out_features=33, bias=True)\n","      (1): LogSoftmax(dim=1)\n","    )\n","  )\n",")"]},"execution_count":7,"metadata":{},"output_type":"execute_result"}],"source":["model = ADDAST(\n","    inp_dim=sc_mix_d[\"train\"].shape[1],\n","    ncls_source=lab_mix_d[\"train\"].shape[1],\n","    **celldart_kwargs\n",")\n","\n","## CellDART uses just one encoder!\n","model.target_encoder = model.source_encoder\n","model.to(device)\n"]},{"cell_type":"markdown","metadata":{},"source":[" ## Pretrain"]},{"cell_type":"code","execution_count":8,"metadata":{},"outputs":[],"source":["pretrain_folder = os.path.join(model_folder, \"pretrain\")\n","\n","if not os.path.isdir(pretrain_folder):\n","    os.makedirs(pretrain_folder)\n"]},{"cell_type":"code","execution_count":9,"metadata":{},"outputs":[],"source":["pre_optimizer = torch.optim.Adam(\n","    model.parameters(), lr=0.001, betas=(0.9, 0.999), eps=1e-07\n",")\n","\n","criterion_clf = nn.KLDivLoss(reduction=\"batchmean\")\n"]},{"cell_type":"code","execution_count":10,"metadata":{},"outputs":[],"source":["def model_loss(x, y_true, model):\n","    x = x.to(torch.float32).to(device)\n","    y_true = y_true.to(torch.float32).to(device)\n","\n","    y_pred = model(x)\n","\n","    loss = criterion_clf(y_pred, y_true)\n","\n","    return loss\n","\n","\n","def compute_acc(dataloader, model):\n","    loss_running = []\n","    mean_weights = []\n","    model.eval()\n","    with torch.no_grad():\n","        for _, batch in enumerate(dataloader):\n","\n","            loss = model_loss(*batch, model)\n","\n","            loss_running.append(loss.item())\n","\n","            # we will weight average by batch size later\n","            mean_weights.append(len(batch))\n","\n","    return np.average(loss_running, weights=mean_weights)\n"]},{"cell_type":"code","execution_count":11,"metadata":{},"outputs":[],"source":["model.pretraining()\n"]},{"cell_type":"code","execution_count":12,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Start pretrain...\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"36bc9e585e894bbaaecafc10b33f096b","version_major":2,"version_minor":0},"text/plain":["Epochs:   0%|          | 0/10 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"9e5ea14f6fc84a88869b9b82b4d4ca79","version_major":2,"version_minor":0},"text/plain":["Batch:   0%|          | 0/40 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["epoch: 0 train loss: 1.254696 validation loss: 1.486211 <-- new best val loss\n","epoch: 1 train loss: 0.903333 validation loss: 1.219224 <-- new best val loss\n","epoch: 2 train loss: 0.720916 validation loss: 1.022733 <-- new best val loss\n","epoch: 3 train loss: 0.625695 validation loss: 0.97935 <-- new best val loss\n","epoch: 4 train loss: 0.585073 validation loss: 0.92795 <-- new best val loss\n","epoch: 5 train loss: 0.562747 validation loss: 0.876444 <-- new best val loss\n","epoch: 6 train loss: 0.541671 validation loss: 0.799501 <-- new best val loss\n","epoch: 7 train loss: 0.525164 validation loss: 0.820431 \n","epoch: 8 train loss: 0.512558 validation loss: 0.726743 <-- new best val loss\n","epoch: 9 train loss: 0.498368 validation loss: 0.691346 <-- new best val loss\n"]}],"source":["# Initialize lists to store loss and accuracy values\n","loss_history = []\n","loss_history_val = []\n","\n","loss_history_running = []\n","\n","# Early Stopping\n","best_loss_val = np.inf\n","early_stop_count = 0\n","\n","# Train\n","print(\"Start pretrain...\")\n","outer = tqdm(total=INITIAL_TRAIN_EPOCHS, desc=\"Epochs\", position=0)\n","inner = tqdm(total=len(dataloader_source_train), desc=f\"Batch\", position=1)\n","\n","checkpoint = {\n","    \"epoch\": -1,\n","    \"model\": model,\n","    \"optimizer\": pre_optimizer,\n","}\n","for epoch in range(INITIAL_TRAIN_EPOCHS):\n","    checkpoint[\"epoch\"] = epoch\n","\n","    # Train mode\n","    model.train()\n","    loss_running = []\n","    mean_weights = []\n","\n","    inner.refresh()  # force print final state\n","    inner.reset()  # reuse bar\n","    for _, batch in enumerate(dataloader_source_train):\n","\n","        pre_optimizer.zero_grad()\n","        loss = model_loss(*batch, model)\n","        loss_running.append(loss.item())\n","        mean_weights.append(len(batch))  # we will weight average by batch size later\n","\n","        loss.backward()\n","        pre_optimizer.step()\n","\n","        inner.update(1)\n","\n","    loss_history.append(np.average(loss_running, weights=mean_weights))\n","    loss_history_running.append(loss_running)\n","\n","    # Evaluate mode\n","    model.eval()\n","    with torch.no_grad():\n","        curr_loss_val = compute_acc(dataloader_source_val, model)\n","        loss_history_val.append(curr_loss_val)\n","\n","    # Print the results\n","    outer.update(1)\n","    print(\n","        \"epoch:\",\n","        epoch,\n","        \"train loss:\",\n","        round(loss_history[-1], 6),\n","        \"validation loss:\",\n","        round(loss_history_val[-1], 6),\n","        end=\" \",\n","    )\n","\n","    # Save the best weights\n","    if curr_loss_val < best_loss_val:\n","        best_loss_val = curr_loss_val\n","        torch.save(checkpoint, os.path.join(pretrain_folder, f\"best_model.pth\"))\n","        early_stop_count = 0\n","\n","        print(\"<-- new best val loss\")\n","    else:\n","        print(\"\")\n","\n","    # Save checkpoint every 10\n","    if epoch % 10 == 0 or epoch >= INITIAL_TRAIN_EPOCHS - 1:\n","        torch.save(checkpoint, os.path.join(pretrain_folder, f\"checkpt{epoch}.pth\"))\n","\n","    # check to see if validation loss has plateau'd\n","    if early_stop_count >= EARLY_STOP_CRIT and epoch >= MIN_EPOCHS - 1:\n","        print(f\"Validation loss plateaued after {early_stop_count} at epoch {epoch}\")\n","        torch.save(checkpoint, os.path.join(pretrain_folder, f\"earlystop{epoch}.pth\"))\n","        break\n","\n","    early_stop_count += 1\n","\n","\n","# Save final model\n","torch.save(checkpoint, os.path.join(pretrain_folder, f\"final_model.pth\"))\n"]},{"cell_type":"markdown","metadata":{},"source":[" ## Adversarial Adaptation"]},{"cell_type":"code","execution_count":13,"metadata":{},"outputs":[],"source":[]},{"cell_type":"code","execution_count":14,"metadata":{},"outputs":[],"source":["advtrain_folder = os.path.join(model_folder, \"advtrain\")\n","\n","if not os.path.isdir(advtrain_folder):\n","    os.makedirs(advtrain_folder)\n"]},{"cell_type":"code","execution_count":15,"metadata":{},"outputs":[],"source":["def batch_generator(data, batch_size):\n","    \"\"\"Generate batches of data.\n","    \n","    Given a list of numpy data, it iterates over the list and returns batches of\n","    the same size.\n","    \"\"\"\n","    all_examples_indices = len(data[0])\n","    while True:\n","        mini_batch_indices = np.random.choice(\n","            all_examples_indices, size=batch_size, replace=False\n","        )\n","        tbr = [k[mini_batch_indices] for k in data]\n","        yield tbr\n"]},{"cell_type":"code","execution_count":16,"metadata":{},"outputs":[],"source":["criterion_dis = nn.CrossEntropyLoss()\n","\n","\n","def discrim_loss_accu(x, y_dis, model):\n","    x = x.to(torch.float32).to(device)\n","\n","    emb = model.source_encoder(x)\n","    y_pred = model.dis(emb)\n","\n","    loss = criterion_dis(y_pred, y_dis)\n","\n","    accu = torch.mean(\n","        (torch.flatten(torch.argmax(y_pred, dim=1)) == y_dis).to(torch.float32)\n","    ).cpu()\n","\n","    return loss, accu\n","\n","\n","def compute_acc_dis(dataloader_source, dataloader_target, model):\n","    len_target = len(dataloader_target)\n","    len_source = len(dataloader_source)\n","\n","    loss_running = []\n","    accu_running = []\n","    mean_weights = []\n","    model.eval()\n","    model.source_encoder.eval()\n","    model.dis.eval()\n","    with torch.no_grad():\n","        for y_val, dl in zip([1, 0], [dataloader_target, dataloader_source]):\n","            for _, (x, _) in enumerate(dl):\n","\n","                y_dis = torch.full(\n","                    (x.shape[0],), y_val, device=device, dtype=torch.long\n","                )\n","\n","                loss, accu = discrim_loss_accu(x, y_dis, model)\n","\n","                accu_running.append(accu)\n","                loss_running.append(loss.item())\n","\n","                # we will weight average by batch size later\n","                mean_weights.append(len(x))\n","\n","    return (\n","        np.average(loss_running, weights=mean_weights),\n","        np.average(accu_running, weights=mean_weights),\n","    )\n"]},{"cell_type":"code","execution_count":17,"metadata":{},"outputs":[],"source":["def train_adversarial(\n","    model,\n","    save_folder,\n","    sc_mix_train_s,\n","    lab_mix_train_s,\n","    mat_sp_train_s,\n","    dataloader_source_train_eval,\n","    dataloader_target_train_eval,\n","):\n","\n","    model.to(device)\n","    model.advtraining()\n","    model.set_encoder(\"source\")\n","\n","    S_batches = batch_generator(\n","        [sc_mix_train_s.copy(), lab_mix_train_s.copy()], BATCH_SIZE\n","    )\n","    T_batches = batch_generator(\n","        [mat_sp_train_s.copy(), np.ones(shape=(len(mat_sp_train_s), 2))], BATCH_SIZE\n","    )\n","\n","    enc_optimizer = torch.optim.Adam(\n","        chain(\n","            model.source_encoder.parameters(),\n","            model.dis.parameters(),\n","            model.clf.parameters(),\n","        ),\n","        lr=0.001,\n","        betas=(0.9, 0.999),\n","        eps=1e-07,\n","    )\n","\n","    dis_optimizer = torch.optim.Adam(\n","        chain(model.source_encoder.parameters(), model.dis.parameters()),\n","        lr=ALPHA_LR * 0.001,\n","        betas=(0.9, 0.999),\n","        eps=1e-07,\n","    )\n","\n","    # Initialize lists to store loss and accuracy values\n","    loss_history_running = []\n","\n","    # Train\n","    print(\"Start adversarial training...\")\n","    outer = tqdm(total=N_ITER, desc=\"Iterations\", position=0)\n","\n","    checkpoint = {\n","        \"epoch\": -1,\n","        \"model\": model,\n","        \"dis_optimizer\": dis_optimizer,\n","        \"enc_optimizer\": enc_optimizer,\n","    }\n","    for iters in range(N_ITER):\n","        checkpoint[\"epoch\"] = iters\n","\n","        model.train()\n","        model.dis.train()\n","        model.clf.train()\n","        model.source_encoder.train()\n","\n","        x_source, y_true = next(S_batches)\n","        x_target, _ = next(T_batches)\n","\n","        ## Train encoder\n","        set_requires_grad(model.source_encoder, True)\n","        set_requires_grad(model.clf, True)\n","        set_requires_grad(model.dis, True)\n","\n","        # save discriminator weights\n","        dis_weights = deepcopy(model.dis.state_dict())\n","        new_dis_weights = {}\n","        for k in dis_weights:\n","            if \"num_batches_tracked\" not in k:\n","                new_dis_weights[k] = dis_weights[k]\n","\n","        dis_weights = new_dis_weights\n","\n","        x_source, x_target, y_true, = (\n","            torch.Tensor(x_source),\n","            torch.Tensor(x_target),\n","            torch.Tensor(y_true),\n","        )\n","        x_source, x_target, y_true, = (\n","            x_source.to(device),\n","            x_target.to(device),\n","            y_true.to(device),\n","        )\n","\n","        x = torch.cat((x_source, x_target))\n","\n","        # save for discriminator later\n","        x_d = x.detach()\n","\n","        # y_dis is the REAL one\n","        y_dis = torch.cat(\n","            [\n","                torch.zeros(x_source.shape[0], device=device, dtype=torch.long),\n","                torch.ones(x_target.shape[0], device=device, dtype=torch.long),\n","            ]\n","        )\n","        y_dis_flipped = 1 - y_dis.detach()\n","\n","        emb = model.source_encoder(x).view(x.shape[0], -1)\n","\n","        y_dis_pred = model.dis(emb)\n","        y_clf_pred = model.clf(emb)\n","\n","        # we use flipped because we want to confuse discriminator\n","        loss_dis = criterion_dis(y_dis_pred, y_dis_flipped)\n","\n","        # Set true = predicted for target samples since we don't know what it is\n","        y_clf_true = torch.cat((y_true, y_clf_pred[-x_target.shape[0] :].detach()))\n","        # Loss fn does mean over all samples including target\n","        loss_clf = criterion_clf(y_clf_pred, y_clf_true)\n","\n","        # Scale back up loss so mean doesn't include target\n","        loss = (x.shape[0] / x_source.shape[0]) * loss_clf + ALPHA * loss_dis\n","\n","        # loss = loss_clf + ALPHA * loss_dis\n","\n","        enc_optimizer.zero_grad()\n","        loss.backward()\n","        enc_optimizer.step()\n","\n","        model.dis.load_state_dict(dis_weights, strict=False)\n","\n","        ## Train discriminator\n","        set_requires_grad(model.source_encoder, True)\n","        set_requires_grad(model.clf, True)\n","        set_requires_grad(model.dis, True)\n","\n","        # save encoder and clf weights\n","        source_encoder_weights = deepcopy(model.source_encoder.state_dict())\n","        clf_weights = deepcopy(model.clf.state_dict())\n","\n","        new_clf_weights = {}\n","        for k in clf_weights:\n","            if \"num_batches_tracked\" not in k:\n","                new_clf_weights[k] = clf_weights[k]\n","\n","        clf_weights = new_clf_weights\n","\n","        new_source_encoder_weights = {}\n","        for k in source_encoder_weights:\n","            if \"num_batches_tracked\" not in k:\n","                new_source_encoder_weights[k] = source_encoder_weights[k]\n","\n","        source_encoder_weights = new_source_encoder_weights\n","\n","        emb = model.source_encoder(x_d).view(x_d.shape[0], -1)\n","        y_pred = model.dis(emb)\n","\n","        # we use the real domain labels to train discriminator\n","        loss = criterion_dis(y_pred, y_dis)\n","\n","        dis_optimizer.zero_grad()\n","        loss.backward()\n","        dis_optimizer.step()\n","\n","        model.clf.load_state_dict(clf_weights, strict=False)\n","        model.source_encoder.load_state_dict(source_encoder_weights, strict=False)\n","\n","        # Save checkpoint every 100\n","        if iters % 100 == 99 or iters >= N_ITER - 1:\n","            torch.save(checkpoint, os.path.join(save_folder, f\"checkpt{iters}.pth\"))\n","\n","            model.eval()\n","            source_loss = compute_acc(dataloader_source_train_eval, model)\n","            _, dis_accu = compute_acc_dis(\n","                dataloader_source_train_eval, dataloader_target_train_eval, model\n","            )\n","\n","            # Print the results\n","            print(\n","                \"iter:\",\n","                iters,\n","                \"source loss:\",\n","                round(source_loss, 6),\n","                \"dis accu:\",\n","                round(dis_accu, 6),\n","            )\n","\n","        outer.update(1)\n","\n","    torch.save(checkpoint, os.path.join(save_folder, f\"final_model.pth\"))\n"]},{"cell_type":"code","execution_count":18,"metadata":{},"outputs":[],"source":["# st_sample_id_l = [SAMPLE_ID_N]\n"]},{"cell_type":"code","execution_count":19,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Adversarial training for ST slide 151509: \n","Start adversarial training...\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"fec98e5571c54cc9895d65c0fc43171c","version_major":2,"version_minor":0},"text/plain":["Iterations:   0%|          | 0/3000 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["iter: 99 source loss: 5.329889 dis accu: 0.831296\n","iter: 199 source loss: 2.493377 dis accu: 0.809512\n","iter: 299 source loss: 2.24339 dis accu: 0.822421\n","iter: 399 source loss: 1.727972 dis accu: 0.832748\n","iter: 499 source loss: 1.399806 dis accu: 0.871798\n","iter: 599 source loss: 1.563935 dis accu: 0.81996\n","iter: 699 source loss: 1.272468 dis accu: 0.808181\n","iter: 799 source loss: 1.92189 dis accu: 0.276615\n","iter: 899 source loss: 1.336929 dis accu: 0.723224\n","iter: 999 source loss: 1.197243 dis accu: 0.319618\n","iter: 1099 source loss: 1.114381 dis accu: 0.488765\n","iter: 1199 source loss: 1.035202 dis accu: 0.647787\n","iter: 1299 source loss: 1.01229 dis accu: 0.770906\n","iter: 1399 source loss: 0.994731 dis accu: 0.68248\n","iter: 1499 source loss: 0.946541 dis accu: 0.733753\n","iter: 1599 source loss: 0.91165 dis accu: 0.583646\n","iter: 1699 source loss: 0.881743 dis accu: 0.528581\n","iter: 1799 source loss: 0.850467 dis accu: 0.537053\n","iter: 1899 source loss: 0.97951 dis accu: 0.734439\n","iter: 1999 source loss: 0.890101 dis accu: 0.90161\n","iter: 2099 source loss: 0.870748 dis accu: 0.565291\n","iter: 2199 source loss: 0.842675 dis accu: 0.269232\n","iter: 2299 source loss: 0.90679 dis accu: 0.003187\n","iter: 2399 source loss: 0.867767 dis accu: 0.293316\n","iter: 2499 source loss: 0.813826 dis accu: 0.114486\n","iter: 2599 source loss: 1.434901 dis accu: 0.537456\n","iter: 2699 source loss: 1.194593 dis accu: 0.105127\n","iter: 2799 source loss: 0.968469 dis accu: 0.304934\n","iter: 2899 source loss: 1.103261 dis accu: 0.365404\n","iter: 2999 source loss: 0.873328 dis accu: 0.15523\n","Adversarial training for ST slide 151510: \n","Start adversarial training...\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"b74ce1c5ec224a0182509713e4bfd6d1","version_major":2,"version_minor":0},"text/plain":["Iterations:   0%|          | 0/3000 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["iter: 99 source loss: 5.770964 dis accu: 0.188073\n","iter: 199 source loss: 4.385024 dis accu: 0.188114\n","iter: 299 source loss: 1.801786 dis accu: 0.839368\n","iter: 399 source loss: 1.650552 dis accu: 0.973695\n","iter: 499 source loss: 1.617005 dis accu: 0.933994\n","iter: 599 source loss: 1.440305 dis accu: 0.994073\n","iter: 699 source loss: 1.147237 dis accu: 0.998376\n","iter: 799 source loss: 1.21829 dis accu: 0.151539\n","iter: 899 source loss: 1.005714 dis accu: 0.903548\n","iter: 999 source loss: 1.027547 dis accu: 0.884793\n","iter: 1099 source loss: 0.98729 dis accu: 0.597508\n","iter: 1199 source loss: 0.921883 dis accu: 0.530527\n","iter: 1299 source loss: 0.880969 dis accu: 0.558253\n","iter: 1399 source loss: 0.826557 dis accu: 0.72063\n","iter: 1499 source loss: 0.852296 dis accu: 0.638224\n","iter: 1599 source loss: 0.857951 dis accu: 0.707356\n","iter: 1699 source loss: 0.875367 dis accu: 0.827799\n","iter: 1799 source loss: 0.807194 dis accu: 0.375457\n","iter: 1899 source loss: 0.744437 dis accu: 0.234513\n","iter: 1999 source loss: 0.671171 dis accu: 0.869652\n","iter: 2099 source loss: 0.657277 dis accu: 0.601364\n","iter: 2199 source loss: 0.642943 dis accu: 0.575952\n","iter: 2299 source loss: 0.658226 dis accu: 0.52801\n","iter: 2399 source loss: 0.810543 dis accu: 0.135707\n","iter: 2499 source loss: 0.626852 dis accu: 0.547455\n","iter: 2599 source loss: 0.575221 dis accu: 0.714541\n","iter: 2699 source loss: 0.582728 dis accu: 0.639523\n","iter: 2799 source loss: 0.588187 dis accu: 0.770277\n","iter: 2899 source loss: 0.582591 dis accu: 0.347853\n","iter: 2999 source loss: 0.557129 dis accu: 0.319802\n","Adversarial training for ST slide 151671: \n","Start adversarial training...\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"04b6986fbed14091b0ca6ac572cd19fd","version_major":2,"version_minor":0},"text/plain":["Iterations:   0%|          | 0/3000 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["iter: 99 source loss: 4.223671 dis accu: 0.829739\n","iter: 199 source loss: 1.597801 dis accu: 0.832974\n","iter: 299 source loss: 1.8905 dis accu: 0.835421\n","iter: 399 source loss: 2.251702 dis accu: 0.830859\n","iter: 499 source loss: 1.538765 dis accu: 0.838698\n","iter: 599 source loss: 1.609873 dis accu: 0.845292\n","iter: 699 source loss: 1.465553 dis accu: 0.835172\n","iter: 799 source loss: 1.30905 dis accu: 0.835462\n","iter: 899 source loss: 1.299996 dis accu: 0.833555\n","iter: 999 source loss: 1.250536 dis accu: 0.951597\n","iter: 1099 source loss: 1.586589 dis accu: 0.743343\n","iter: 1199 source loss: 1.134781 dis accu: 0.850145\n","iter: 1299 source loss: 1.129024 dis accu: 0.834094\n","iter: 1399 source loss: 1.096065 dis accu: 0.732518\n","iter: 1499 source loss: 1.062745 dis accu: 0.645334\n","iter: 1599 source loss: 1.062451 dis accu: 0.446786\n","iter: 1699 source loss: 1.011898 dis accu: 0.53061\n","iter: 1799 source loss: 0.990317 dis accu: 0.381916\n","iter: 1899 source loss: 0.959217 dis accu: 0.613314\n","iter: 1999 source loss: 0.923507 dis accu: 0.596516\n","iter: 2099 source loss: 0.896159 dis accu: 0.578474\n","iter: 2199 source loss: 0.882005 dis accu: 0.615263\n","iter: 2299 source loss: 0.83077 dis accu: 0.872128\n","iter: 2399 source loss: 0.907871 dis accu: 0.425384\n","iter: 2499 source loss: 0.827228 dis accu: 0.867316\n","iter: 2599 source loss: 0.837644 dis accu: 0.37416\n","iter: 2699 source loss: 0.828455 dis accu: 0.602281\n","iter: 2799 source loss: 0.847515 dis accu: 0.965491\n","iter: 2899 source loss: 0.794047 dis accu: 0.921609\n","iter: 2999 source loss: 1.138717 dis accu: 0.182331\n","Adversarial training for ST slide 151508: \n","Start adversarial training...\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"7a505085e1ee4fd2b6e90d3807643458","version_major":2,"version_minor":0},"text/plain":["Iterations:   0%|          | 0/3000 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["iter: 99 source loss: 6.273739 dis accu: 0.180036\n","iter: 199 source loss: 4.396993 dis accu: 0.17979\n","iter: 299 source loss: 2.014038 dis accu: 0.254716\n","iter: 399 source loss: 1.889748 dis accu: 0.179954\n","iter: 499 source loss: 1.52598 dis accu: 0.844242\n","iter: 599 source loss: 1.76749 dis accu: 0.844816\n","iter: 699 source loss: 1.32588 dis accu: 0.63513\n","iter: 799 source loss: 1.17573 dis accu: 0.470103\n","iter: 899 source loss: 1.116491 dis accu: 0.620612\n","iter: 999 source loss: 1.009376 dis accu: 0.738517\n","iter: 1099 source loss: 0.962529 dis accu: 0.761852\n","iter: 1199 source loss: 0.922027 dis accu: 0.714977\n","iter: 1299 source loss: 0.886619 dis accu: 0.645669\n","iter: 1399 source loss: 0.874757 dis accu: 0.659203\n","iter: 1499 source loss: 0.805668 dis accu: 0.874303\n","iter: 1599 source loss: 0.839437 dis accu: 0.295399\n","iter: 1699 source loss: 0.847576 dis accu: 0.250656\n","iter: 1799 source loss: 0.809087 dis accu: 0.069267\n","iter: 1899 source loss: 0.813877 dis accu: 0.350312\n","iter: 1999 source loss: 0.799558 dis accu: 0.276493\n","iter: 2099 source loss: 0.8121 dis accu: 0.952633\n","iter: 2199 source loss: 0.812071 dis accu: 0.887016\n","iter: 2299 source loss: 0.824845 dis accu: 0.90625\n","iter: 2399 source loss: 0.802984 dis accu: 0.921793\n","iter: 2499 source loss: 0.952495 dis accu: 0.433399\n","iter: 2599 source loss: 0.847427 dis accu: 0.101952\n","iter: 2699 source loss: 0.846464 dis accu: 0.239501\n","iter: 2799 source loss: 0.748425 dis accu: 0.680282\n","iter: 2899 source loss: 0.838055 dis accu: 0.94804\n","iter: 2999 source loss: 1.65561 dis accu: 0.179626\n","Adversarial training for ST slide 151670: \n","Start adversarial training...\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"dafca6b430f7480cb5197715ec118410","version_major":2,"version_minor":0},"text/plain":["Iterations:   0%|          | 0/3000 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["iter: 99 source loss: 5.880369 dis accu: 0.148864\n","iter: 199 source loss: 3.81105 dis accu: 0.148864\n","iter: 299 source loss: 2.37056 dis accu: 0.944378\n","iter: 399 source loss: 1.613185 dis accu: 0.979913\n","iter: 499 source loss: 1.448887 dis accu: 0.937739\n","iter: 599 source loss: 1.54659 dis accu: 0.98319\n","iter: 699 source loss: 1.296325 dis accu: 0.723253\n","iter: 799 source loss: 1.113409 dis accu: 0.754149\n","iter: 899 source loss: 1.103869 dis accu: 0.920972\n","iter: 999 source loss: 1.01698 dis accu: 0.752149\n","iter: 1099 source loss: 0.990372 dis accu: 0.631798\n","iter: 1199 source loss: 0.937003 dis accu: 0.640565\n","iter: 1299 source loss: 0.984528 dis accu: 0.86135\n","iter: 1399 source loss: 0.873027 dis accu: 0.416291\n","iter: 1499 source loss: 0.841154 dis accu: 0.522385\n","iter: 1599 source loss: 0.783788 dis accu: 0.340114\n","iter: 1699 source loss: 0.76382 dis accu: 0.742233\n","iter: 1799 source loss: 0.767339 dis accu: 0.789727\n","iter: 1899 source loss: 0.733168 dis accu: 0.586433\n","iter: 1999 source loss: 0.65894 dis accu: 0.667716\n","iter: 2099 source loss: 0.645391 dis accu: 0.605073\n","iter: 2199 source loss: 0.631053 dis accu: 0.6944\n","iter: 2299 source loss: 0.644391 dis accu: 0.474679\n","iter: 2399 source loss: 0.93916 dis accu: 0.131926\n","iter: 2499 source loss: 0.686871 dis accu: 0.246021\n","iter: 2599 source loss: 0.564571 dis accu: 0.740318\n","iter: 2699 source loss: 0.53775 dis accu: 0.788237\n","iter: 2799 source loss: 0.542152 dis accu: 0.673504\n","iter: 2899 source loss: 0.52755 dis accu: 0.298706\n","iter: 2999 source loss: 0.59291 dis accu: 0.14963\n","Adversarial training for ST slide 151507: \n","Start adversarial training...\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"92613350f27846cf95b0fe417b123046","version_major":2,"version_minor":0},"text/plain":["Iterations:   0%|          | 0/3000 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["iter: 99 source loss: 4.958266 dis accu: 0.851853\n","iter: 199 source loss: 2.746567 dis accu: 0.572608\n","iter: 299 source loss: 2.677324 dis accu: 0.954966\n","iter: 399 source loss: 2.139 dis accu: 0.175638\n","iter: 499 source loss: 2.174251 dis accu: 0.206142\n","iter: 599 source loss: 1.477738 dis accu: 0.8611\n","iter: 699 source loss: 1.416895 dis accu: 0.870924\n","iter: 799 source loss: 1.236058 dis accu: 0.796128\n","iter: 899 source loss: 1.0784 dis accu: 0.949104\n","iter: 999 source loss: 1.048647 dis accu: 0.877198\n","iter: 1099 source loss: 1.036816 dis accu: 0.718608\n","iter: 1199 source loss: 1.032866 dis accu: 0.174152\n","iter: 1299 source loss: 0.935641 dis accu: 0.369727\n","iter: 1399 source loss: 0.906779 dis accu: 0.353463\n","iter: 1499 source loss: 0.849789 dis accu: 0.513869\n","iter: 1599 source loss: 0.882661 dis accu: 0.197639\n","iter: 1699 source loss: 0.847478 dis accu: 0.450425\n","iter: 1799 source loss: 0.84184 dis accu: 0.919756\n","iter: 1899 source loss: 0.760778 dis accu: 0.572567\n","iter: 1999 source loss: 0.73001 dis accu: 0.620078\n","iter: 2099 source loss: 0.779591 dis accu: 0.18088\n","iter: 2199 source loss: 0.738148 dis accu: 0.341204\n","iter: 2299 source loss: 0.71392 dis accu: 0.473376\n","iter: 2399 source loss: 0.668968 dis accu: 0.836457\n","iter: 2499 source loss: 0.688827 dis accu: 0.426195\n","iter: 2599 source loss: 0.606231 dis accu: 0.522001\n","iter: 2699 source loss: 0.616948 dis accu: 0.142326\n","iter: 2799 source loss: 0.575835 dis accu: 0.631924\n","iter: 2899 source loss: 0.577397 dis accu: 0.825394\n","iter: 2999 source loss: 0.593296 dis accu: 0.660654\n","Adversarial training for ST slide 151674: \n","Start adversarial training...\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"8e07dffbdcfc41a883558a2c73a05014","version_major":2,"version_minor":0},"text/plain":["Iterations:   0%|          | 0/3000 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["iter: 99 source loss: 5.602354 dis accu: 0.16842\n","iter: 199 source loss: 4.168841 dis accu: 0.155156\n","iter: 299 source loss: 2.674257 dis accu: 0.727453\n","iter: 399 source loss: 1.592845 dis accu: 0.156169\n","iter: 499 source loss: 1.498531 dis accu: 0.845098\n","iter: 599 source loss: 1.590232 dis accu: 0.800955\n","iter: 699 source loss: 1.246642 dis accu: 0.851138\n","iter: 799 source loss: 1.18041 dis accu: 0.282558\n","iter: 899 source loss: 1.069776 dis accu: 0.418494\n","iter: 999 source loss: 0.994856 dis accu: 0.880877\n","iter: 1099 source loss: 0.99097 dis accu: 0.539137\n","iter: 1199 source loss: 0.888884 dis accu: 0.628395\n","iter: 1299 source loss: 0.845087 dis accu: 0.851603\n","iter: 1399 source loss: 0.825884 dis accu: 0.592447\n","iter: 1499 source loss: 0.829222 dis accu: 0.190597\n","iter: 1599 source loss: 0.861523 dis accu: 0.842437\n","iter: 1699 source loss: 0.836888 dis accu: 0.95083\n","iter: 1799 source loss: 0.862771 dis accu: 0.319731\n","iter: 1899 source loss: 0.79398 dis accu: 0.911798\n","iter: 1999 source loss: 0.827572 dis accu: 0.917881\n","iter: 2099 source loss: 0.851701 dis accu: 0.34571\n","iter: 2199 source loss: 0.806119 dis accu: 0.871288\n","iter: 2299 source loss: 0.78785 dis accu: 0.081612\n","iter: 2399 source loss: 0.814954 dis accu: 0.237359\n","iter: 2499 source loss: 0.810985 dis accu: 0.178769\n","iter: 2599 source loss: 0.826323 dis accu: 0.188189\n","iter: 2699 source loss: 0.9053 dis accu: 0.093693\n","iter: 2799 source loss: 0.748339 dis accu: 0.899548\n","iter: 2899 source loss: 0.722315 dis accu: 0.486292\n","iter: 2999 source loss: 0.84193 dis accu: 0.362227\n","Adversarial training for ST slide 151676: \n","Start adversarial training...\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"e164cf98eb434fa7a80767778a867035","version_major":2,"version_minor":0},"text/plain":["Iterations:   0%|          | 0/3000 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["iter: 99 source loss: 5.982381 dis accu: 0.151577\n","iter: 199 source loss: 3.611098 dis accu: 0.147869\n","iter: 299 source loss: 2.503056 dis accu: 0.147485\n","iter: 399 source loss: 1.714815 dis accu: 0.893691\n","iter: 499 source loss: 2.10442 dis accu: 0.52191\n","iter: 599 source loss: 1.578095 dis accu: 0.772208\n","iter: 699 source loss: 1.105151 dis accu: 0.958653\n","iter: 799 source loss: 1.06441 dis accu: 0.833419\n","iter: 899 source loss: 1.033318 dis accu: 0.254561\n","iter: 999 source loss: 1.006135 dis accu: 0.281202\n","iter: 1099 source loss: 0.912237 dis accu: 0.602984\n","iter: 1199 source loss: 0.905776 dis accu: 0.491006\n","iter: 1299 source loss: 0.885401 dis accu: 0.17954\n","iter: 1399 source loss: 0.857631 dis accu: 0.577067\n","iter: 1499 source loss: 0.821352 dis accu: 0.676684\n","iter: 1599 source loss: 0.837948 dis accu: 0.731586\n","iter: 1699 source loss: 0.753309 dis accu: 0.318585\n","iter: 1799 source loss: 0.797195 dis accu: 0.337766\n","iter: 1899 source loss: 0.908319 dis accu: 0.432609\n","iter: 1999 source loss: 0.853248 dis accu: 0.285337\n","iter: 2099 source loss: 0.737047 dis accu: 0.970673\n","iter: 2199 source loss: 0.861832 dis accu: 0.949702\n","iter: 2299 source loss: 0.858571 dis accu: 0.999446\n","iter: 2399 source loss: 1.174075 dis accu: 0.149574\n","iter: 2499 source loss: 1.286944 dis accu: 0.312404\n","iter: 2599 source loss: 1.296427 dis accu: 0.107076\n","iter: 2699 source loss: 1.089578 dis accu: 0.257886\n","iter: 2799 source loss: 1.014189 dis accu: 0.997101\n","iter: 2899 source loss: 1.108535 dis accu: 0.279284\n","iter: 2999 source loss: 1.005867 dis accu: 0.99919\n","Adversarial training for ST slide 151675: \n","Start adversarial training...\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"0e2b61ba333148b7900c7fb348820b4e","version_major":2,"version_minor":0},"text/plain":["Iterations:   0%|          | 0/3000 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["iter: 99 source loss: 4.818593 dis accu: 0.152255\n","iter: 199 source loss: 3.179957 dis accu: 0.961216\n","iter: 299 source loss: 1.654203 dis accu: 0.97567\n","iter: 399 source loss: 1.695862 dis accu: 0.152255\n","iter: 499 source loss: 2.311325 dis accu: 0.152255\n","iter: 599 source loss: 1.556799 dis accu: 0.450746\n","iter: 699 source loss: 1.349708 dis accu: 0.970965\n","iter: 799 source loss: 1.329499 dis accu: 0.580154\n","iter: 899 source loss: 1.27181 dis accu: 0.879239\n","iter: 999 source loss: 1.142508 dis accu: 0.407341\n","iter: 1099 source loss: 1.037918 dis accu: 0.601772\n","iter: 1199 source loss: 0.972496 dis accu: 0.849356\n","iter: 1299 source loss: 0.968495 dis accu: 0.769456\n","iter: 1399 source loss: 0.94617 dis accu: 0.686716\n","iter: 1499 source loss: 0.881424 dis accu: 0.75462\n","iter: 1599 source loss: 0.885129 dis accu: 0.526322\n","iter: 1699 source loss: 0.841185 dis accu: 0.762504\n","iter: 1799 source loss: 0.858134 dis accu: 0.813793\n","iter: 1899 source loss: 0.794863 dis accu: 0.725161\n","iter: 1999 source loss: 0.797664 dis accu: 0.693879\n","iter: 2099 source loss: 0.76951 dis accu: 0.850246\n","iter: 2199 source loss: 0.770837 dis accu: 0.537386\n","iter: 2299 source loss: 0.739608 dis accu: 0.90874\n","iter: 2399 source loss: 0.729647 dis accu: 0.657002\n","iter: 2499 source loss: 0.762535 dis accu: 0.908571\n","iter: 2599 source loss: 0.846352 dis accu: 0.907511\n","iter: 2699 source loss: 0.914134 dis accu: 0.937013\n","iter: 2799 source loss: 1.314437 dis accu: 0.137462\n","iter: 2899 source loss: 0.871495 dis accu: 0.971261\n","iter: 2999 source loss: 1.117946 dis accu: 0.873644\n","Adversarial training for ST slide 151673: \n","Start adversarial training...\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"3828d7dabb58481c9df57826cfd2450e","version_major":2,"version_minor":0},"text/plain":["Iterations:   0%|          | 0/3000 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["iter: 99 source loss: 4.5874 dis accu: 0.153941\n","iter: 199 source loss: 3.175754 dis accu: 0.153941\n","iter: 299 source loss: 2.037589 dis accu: 0.154998\n","iter: 399 source loss: 1.536415 dis accu: 0.846271\n","iter: 499 source loss: 1.368904 dis accu: 0.953974\n","iter: 599 source loss: 1.543801 dis accu: 0.736706\n","iter: 699 source loss: 1.105701 dis accu: 0.933331\n","iter: 799 source loss: 1.102988 dis accu: 0.929481\n","iter: 899 source loss: 1.066866 dis accu: 0.600322\n","iter: 999 source loss: 1.005063 dis accu: 0.326875\n","iter: 1099 source loss: 0.968182 dis accu: 0.661872\n","iter: 1199 source loss: 0.942358 dis accu: 0.312196\n","iter: 1299 source loss: 0.874894 dis accu: 0.727019\n","iter: 1399 source loss: 0.945905 dis accu: 0.500275\n","iter: 1499 source loss: 0.814914 dis accu: 0.406193\n","iter: 1599 source loss: 0.725077 dis accu: 0.750624\n","iter: 1699 source loss: 0.744203 dis accu: 0.457972\n","iter: 1799 source loss: 0.720768 dis accu: 0.589788\n","iter: 1899 source loss: 0.63961 dis accu: 0.524134\n","iter: 1999 source loss: 0.682763 dis accu: 0.206269\n","iter: 2099 source loss: 0.620507 dis accu: 0.865688\n","iter: 2199 source loss: 0.626575 dis accu: 0.398832\n","iter: 2299 source loss: 0.571339 dis accu: 0.153941\n","iter: 2399 source loss: 0.578849 dis accu: 0.377554\n","iter: 2499 source loss: 0.596019 dis accu: 0.857227\n","iter: 2599 source loss: 0.613247 dis accu: 0.800372\n","iter: 2699 source loss: 0.53762 dis accu: 0.811921\n","iter: 2799 source loss: 0.532279 dis accu: 0.797707\n","iter: 2899 source loss: 0.506419 dis accu: 0.553323\n","iter: 2999 source loss: 0.498104 dis accu: 0.453742\n","Adversarial training for ST slide 151672: \n","Start adversarial training...\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"c09b4b5709c948b390171c88cdddb69e","version_major":2,"version_minor":0},"text/plain":["Iterations:   0%|          | 0/3000 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["iter: 99 source loss: 7.499743 dis accu: 0.167187\n","iter: 199 source loss: 1.746726 dis accu: 0.879034\n","iter: 299 source loss: 1.864487 dis accu: 0.846679\n","iter: 399 source loss: 1.657976 dis accu: 0.837726\n","iter: 499 source loss: 1.647039 dis accu: 0.835728\n","iter: 599 source loss: 1.565954 dis accu: 0.837352\n","iter: 699 source loss: 1.434672 dis accu: 0.854674\n","iter: 799 source loss: 1.342416 dis accu: 0.848595\n","iter: 899 source loss: 1.538955 dis accu: 0.880866\n","iter: 999 source loss: 1.354575 dis accu: 0.833729\n","iter: 1099 source loss: 1.116913 dis accu: 0.856257\n","iter: 1199 source loss: 1.110342 dis accu: 0.979513\n","iter: 1299 source loss: 1.067139 dis accu: 0.901686\n","iter: 1399 source loss: 1.05278 dis accu: 0.213991\n","iter: 1499 source loss: 1.014133 dis accu: 0.830065\n","iter: 1599 source loss: 1.047283 dis accu: 0.656007\n","iter: 1699 source loss: 0.999851 dis accu: 0.987091\n","iter: 1799 source loss: 1.020417 dis accu: 0.256048\n","iter: 1899 source loss: 0.988247 dis accu: 0.975557\n","iter: 1999 source loss: 0.988916 dis accu: 0.83477\n","iter: 2099 source loss: 1.157448 dis accu: 0.483906\n","iter: 2199 source loss: 1.060595 dis accu: 0.24568\n","iter: 2299 source loss: 1.02378 dis accu: 0.142244\n","iter: 2399 source loss: 0.986584 dis accu: 0.980679\n","iter: 2499 source loss: 1.172056 dis accu: 0.137039\n","iter: 2599 source loss: 1.14172 dis accu: 0.911639\n","iter: 2699 source loss: 1.118137 dis accu: 0.998418\n","iter: 2799 source loss: 1.054101 dis accu: 0.997668\n","iter: 2899 source loss: 1.205178 dis accu: 0.816157\n","iter: 2999 source loss: 1.108666 dis accu: 0.825318\n","Adversarial training for ST slide 151669: \n","Start adversarial training...\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"1b5564e1f190478dbb7104453dde593c","version_major":2,"version_minor":0},"text/plain":["Iterations:   0%|          | 0/3000 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["iter: 99 source loss: 4.526574 dis accu: 0.154685\n","iter: 199 source loss: 4.648291 dis accu: 0.98563\n","iter: 299 source loss: 1.783121 dis accu: 0.91467\n","iter: 399 source loss: 1.545641 dis accu: 0.7569\n","iter: 499 source loss: 1.591211 dis accu: 0.745911\n","iter: 599 source loss: 1.35349 dis accu: 0.99459\n","iter: 699 source loss: 1.205744 dis accu: 0.973754\n","iter: 799 source loss: 1.26488 dis accu: 0.14209\n","iter: 899 source loss: 1.06863 dis accu: 0.58924\n","iter: 999 source loss: 0.96142 dis accu: 0.790753\n","iter: 1099 source loss: 0.935498 dis accu: 0.725244\n","iter: 1199 source loss: 0.953202 dis accu: 0.28735\n","iter: 1299 source loss: 0.850594 dis accu: 0.369046\n","iter: 1399 source loss: 0.920641 dis accu: 0.532564\n","iter: 1499 source loss: 0.868406 dis accu: 0.713706\n","iter: 1599 source loss: 0.784912 dis accu: 0.464013\n","iter: 1699 source loss: 0.737416 dis accu: 0.62136\n","iter: 1799 source loss: 0.704578 dis accu: 0.374202\n","iter: 1899 source loss: 0.684682 dis accu: 0.441909\n","iter: 1999 source loss: 0.694103 dis accu: 0.393305\n","iter: 2099 source loss: 0.647477 dis accu: 0.316005\n","iter: 2199 source loss: 0.690686 dis accu: 0.75728\n","iter: 2299 source loss: 0.736216 dis accu: 0.888678\n","iter: 2399 source loss: 0.619226 dis accu: 0.794683\n","iter: 2499 source loss: 0.702834 dis accu: 0.239212\n","iter: 2599 source loss: 0.673061 dis accu: 0.864545\n","iter: 2699 source loss: 0.577958 dis accu: 0.519547\n","iter: 2799 source loss: 0.665236 dis accu: 0.13816\n","iter: 2899 source loss: 0.589032 dis accu: 0.883352\n","iter: 2999 source loss: 1.600555 dis accu: 0.046997\n"]}],"source":["if TRAIN_USING_ALL_ST_SAMPLES:\n","    print(f\"Adversarial training for all ST slides\")\n","    save_folder = advtrain_folder\n","\n","    best_checkpoint = torch.load(os.path.join(pretrain_folder, f\"final_model.pth\"))\n","    model = best_checkpoint[\"model\"]\n","    model.to(device)\n","    model.advtraining()\n","\n","    train_adversarial(\n","        model,\n","        save_folder,\n","        sc_mix_d[\"train\"],\n","        lab_mix_d[\"train\"],\n","        mat_sp_train_s,\n","        dataloader_source_train,\n","        dataloader_target_train,\n","    )\n","\n","else:\n","    for sample_id in st_sample_id_l:\n","        print(f\"Adversarial training for ST slide {sample_id}: \")\n","\n","        save_folder = os.path.join(advtrain_folder, sample_id)\n","        if not os.path.isdir(save_folder):\n","            os.makedirs(save_folder)\n","\n","        best_checkpoint = torch.load(os.path.join(pretrain_folder, f\"final_model.pth\"))\n","        model = best_checkpoint[\"model\"]\n","        model.to(device)\n","        model.advtraining()\n","\n","        train_adversarial(\n","            model,\n","            save_folder,\n","            sc_mix_d[\"train\"],\n","            lab_mix_d[\"train\"],\n","            mat_sp_d[\"train\"][sample_id],\n","            dataloader_source_train,\n","            dataloader_target_train_d[sample_id],\n","        )\n"]},{"cell_type":"code","execution_count":20,"metadata":{},"outputs":[],"source":["# if TRAIN_USING_ALL_ST_SAMPLES:\n","#     best_checkpoint = torch.load(os.path.join(advtrain_folder, f\"final_model.pth\"))\n","# else:\n","#     best_checkpoint = torch.load(\n","#         os.path.join(advtrain_folder, SAMPLE_ID_N, f\"final_model.pth\")\n","#     )\n","\n","# model = best_checkpoint[\"model\"]\n","# model.to(device)\n","\n","# model.eval()\n","# model.set_encoder(\"source\")\n","\n","# pred_mix = (\n","#     torch.exp(model(torch.Tensor(sc_mix_test_s).to(device)))\n","#     .detach()\n","#     .cpu()\n","#     .numpy()\n","# )\n","\n","# cell_type_nums = sc_sub_dict.keys()\n","# nrows = ceil(len(cell_type_nums) / 5)\n","\n","# line_kws = {\"color\": \"tab:orange\"}\n","# scatter_kws = {\"s\": 5}\n","\n","# props = dict(facecolor=\"w\", alpha=0.5)\n","\n","# fig, ax = plt.subplots(\n","#     nrows,\n","#     5,\n","#     figsize=(25, 5 * nrows),\n","#     constrained_layout=True,\n","#     sharex=False,\n","#     sharey=True,\n","# )\n","# for i, visnum in enumerate(cell_type_nums):\n","#     sns.regplot(\n","#         x=pred_mix[:, visnum],\n","#         y=lab_mix_d[\"test\"][:, visnum],\n","#         line_kws=line_kws,\n","#         scatter_kws=scatter_kws,\n","#         ax=ax.flat[i],\n","#     ).set_title(sc_sub_dict[visnum])\n","\n","#     ax.flat[i].set_aspect(\"equal\")\n","#     ax.flat[i].set_xlabel(\"Predicted Proportion\")\n","\n","#     if i % 5 == 0:\n","#         ax.flat[i].set_ylabel(\"True Proportion\")\n","#     else:\n","#         ax.flat[i].set_ylabel(\"\")\n","#     ax.flat[i].set_xlim([0, 1])\n","#     ax.flat[i].set_ylim([0, 1])\n","\n","#     textstr = (\n","#         f\"MSE: {mean_squared_error(pred_mix[:,visnum], lab_mix_d[\"test\"][:,visnum]):.5f}\"\n","#     )\n","\n","#     # place a text box in upper left in axes coords\n","#     ax.flat[i].text(\n","#         0.95,\n","#         0.05,\n","#         textstr,\n","#         transform=ax.flat[i].transAxes,\n","#         verticalalignment=\"bottom\",\n","#         horizontalalignment=\"right\",\n","#         bbox=props,\n","#     )\n","\n","# for i in range(len(cell_type_nums), nrows * 5):\n","#     ax.flat[i].axis(\"off\")\n","\n","# plt.show()\n"]}],"metadata":{"kernelspec":{"display_name":"Python 3.10.4 ('agreda')","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.4"},"orig_nbformat":4,"vscode":{"interpreter":{"hash":"330b2d1c36bdd59efd1cb99466680f0cb310a0929e0186587128f5e2b14c88ce"}}},"nbformat":4,"nbformat_minor":2}
